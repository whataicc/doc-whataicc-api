[{"id":0,"href":"/docs/otherai/chat/cherrystudio/","title":"Cherry Studio","section":"对话客户端类","content":" Cherry Studio # Cherry Studio 配置教程 # Cherry Studio 项目简介 # Cherry Studio 是一款开源的多模型桌面客户端，旨在为用户提供一个统一、高效的AI服务平台。它兼容Windows、macOS 和Linux 三大操作系统，集成了包括OpenAI、DeepSeek、Gemini 等在内的多种主流大语言模型，并支持本地模型的运行。\n主要特点 # **多平台支持：**支持 Windows、macOS 和 Linux。\n**多模型支持：**集成 OpenAI、DeepSeek、Gemini 等多种主流大语言模型，支持本地模型。\n**AI助手与对话：**内置超过300个预配置的AI助手，支持创建自定义AI助手，支持与多个AI模型同时对话。\n**知识库管理：**支持导入多种格式文件，构建个人AI知识库。\n**AI绘画及其他集成工具：**集成AI绘画、翻译、全局搜索、话题管理、WebDAV文件管理、Mermaid图表可视化等功能。\n自定义界面： 支持主题切换、自定义CSS、会话布局、消息样式、头像设置等。\n**集成外部服务：**支持WebDAV、Notion、Tavily等服务集成。\n配置方式 # 一、获取API秘钥（key） # 进入令牌页面（可点击下方链接直达），复制初始令牌或创建一个新的令牌，\n二、填入CherryStudio # 进入设置\u0026ndash;找到模型服务\u0026ndash;找到 NewAPI\n填入API秘钥 和 API 地址\n打开右上角开关\n三、添加模型 # 选择并添加你所需要的模型，回到对话页面\nCherry Studio界面UI # "},{"id":1,"href":"/docs/otherai/devtools/claudecode/","title":"Claude code 配置方式","section":"编程工具类","content":" Claude code 配置方式 # Claude Code 是 Anthropic 官方推出的命令行工具，为开发者提供强大的 AI 辅助编程体验。支持智能代码生成、代码分析、调试助手等功能。\n🚀 主要功能 # 智能代码生成 - 快速生成高质量代码\n代码分析 - 深度理解和分析代码结构\n调试助手 - 智能发现和修复代码问题\n文档生成 - 自动生成代码文档\n命令行集成 - 无缝集成到开发流程\n⭐本站专属功能 # 本站所有LLM 模型均支持在 Claude code 中使用\n如果 Claude code 无法修改调用模型，可参考教程 令牌 中，设置模型转发\n📦 安装步骤 # Mac \u0026amp; Liunx 配置方式 # 1. 安装 Node.js # 确保系统已安装 Node.js 18+ 版本\n安装 Homebrew (mac推荐) # 如果尚未安装 Homebrew：\n/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 2. 安装 Node.js # 使用 Homebrew：\nbrew install node 2. 安装 Claude Code # npm install -g @anthropic-ai/claude-code 3. 配置 API 密钥 # 获取 Auth Token (参考添加令牌文档 # 方法一：使用 Bash（推荐） # echo \u0026#39;export ANTHROPIC_AUTH_TOKEN=\u0026#34;sk-xxx\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile echo \u0026#39;export ANTHROPIC_BASE_URL=\u0026#34;https://api.whatai.cc\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile source ~/.bash_profile 方法二：使用 Zsh（如果使用 Oh My Zsh） # echo \u0026#39;export ANTHROPIC_AUTH_TOKEN=\u0026#34;sk-xxx\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;export ANTHROPIC_BASE_URL=\u0026#34;https://api.whatai.cc\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc 注意： 永久设置后需要重启终端才能生效。\n4. 启动使用 Claude Code # # 进入项目目录 cd your-project-folder # 启动 Claude Code claude 首次启动后需要先进行主题的选择等操作：\n• 选择喜欢的主题（回车）\n• 确认安全须知（回车）\n• 使用默认 Terminal 配置（回车）\n• 信任工作目录（回车）\n• 开始编程！🚀\nWindows配置方式 # 1、管理员权限启动cmd\n1. 安装 Node.js # 访问 Node.JS 官网，点击最新版本，选择对应的操作系统和版本下载即可\n下载后双击安装，之后一直点击下一步。安装完成后，打开 CMD 窗口，执行命令验证安装：\nnode -v 2、设置 npm 配置,告诉 npm 在安装包时忽略执行包中的脚本（如 preinstall、postinstall 等）,设置完重新启动CMD\nsetx NPM_CONFIG_IGNORE_SCRIPTS true 3、安装 Claude Code\nnpm install -g @anthropic-ai/claude-code 4、配置 SHELL 环境变量\n方法一：图形化配置（推荐，永久生效） # a. 右键点击 \u0026ldquo;此电脑\u0026rdquo; → 选择 \u0026ldquo;属性\u0026rdquo;\nb. 点击 \u0026ldquo;高级系统设置\u0026rdquo;\nc. 在 \u0026ldquo;系统属性\u0026rdquo; 窗口中点击 \u0026ldquo;环境变量\u0026rdquo;\n重要：在 \u0026ldquo;系统变量\u0026rdquo; 部分点击 \u0026ldquo;新建\u0026rdquo;（多人共享电脑可选择 \u0026ldquo;用户变量\u0026rdquo;）\nd. 添加以下两个变量：\n变量名：ANTHROPIC_AUTH_TOKEN，变量值：sk-xxx\n变量名：ANTHROPIC_BASE_URL，变量值：https://api.whatai.cc\ne. 点击 \u0026ldquo;确定\u0026rdquo; 保存\n方法二：PowerShell（永久设置） # [Environment]::SetEnvironmentVariable(\u0026#34;ANTHROPIC_AUTH_TOKEN\u0026#34;, \u0026#34;sk-xxx\u0026#34;, \u0026#34;User\u0026#34;) [Environment]::SetEnvironmentVariable(\u0026#34;ANTHROPIC_BASE_URL\u0026#34;, \u0026#34;https://api.whatai.cc\u0026#34;, \u0026#34;User\u0026#34;) 方法三：命令提示符（永久设置） # CMD\nsetx ANTHROPIC_AUTH_TOKEN \u0026#34;sk-xxx\u0026#34; setx ANTHROPIC_BASE_URL \u0026#34;https://api.whatai.cc\u0026#34; 注意： 永久设置后需要重启终端才能生效。推荐使用永久配置方式。\n方法四：通过settings.json 设置 # 找到 settings.json 文件，如果没有请创建\nC:\\Users\\{user}\\.claude\\settings.json 设置 API 信息，保存\n{ \u0026#34;env\u0026#34;: { \u0026#34;ANTHROPIC_MODEL\u0026#34;: \u0026#34;claude-sonnet-4-20250514\u0026#34;, \u0026#34;ANTHROPIC_SMALL_FAST_MODEL\u0026#34;: \u0026#34;claude-sonnet-4-20250514\u0026#34;, \u0026#34;ANTHROPIC_BASE_URL\u0026#34;: \u0026#34;https://api.whatai.cc\u0026#34;, \u0026#34;ANTHROPIC_AUTH_TOKEN\u0026#34;: \u0026#34;sk-AG2\u0026#34; } } setx SHELL \u0026#34;C:\\Program Files\\Git\\bin\\bash.exe\u0026#34; #这里要换成你的路径， # 如果不知道，可以执行 where git 找一下 5、添加 npm 环境变量\nC:\\Users\\y.xie\\.npm-global # 添加Windows环境变量，同样要设置为你的路径，在npm安装包里面 # 如果不知道，可以执行 npm config get prefix 找一下 将其添加到 Windows 的环境变量（PATH），关闭并重新打开你的终端窗口（CMD / PowerShell / Git Bash），使设置生效。\n6、设置API配置\n7、重启开发环境\n8、enjoy!!\n# 进入项目目录 cd your-project-folder # 启动 Claude Code claude 🎯 常用命令 # claude - 启动交互模式\nclaude \u0026quot;task\u0026quot; - 运行一次性任务\nclaude commit - 创建 Git 提交\n/help - 显示可用命令\n/clear - 清除对话历史\n/review - 请求代码审查\n💡 使用示例 # # 代码生成 \u0026gt; 请帮我写一个 Python 函数，用于计算斐波那契数列 # 代码审查 claude \u0026#34;review this code for potential bugs\u0026#34; # 自动提交 claude commit 切换模型 # 使用 Claude Code 命令：\n/model [model id] 默认模型为Sonnet 4，你可以用效果更好的Opus 4：\nopus\n/model opus 或者，换成其他 claude 模型：\nsonnet 3.7\nsonnet 3.5\n/model claude-3-7-sonnet-20250219 Kimi K2 支持启动 Claude Code 之后，只需要运行指令\n/model moonshotai/kimi-k2-instruct 其他 LLM 模型均支持使用，比如 Openai、Gemini、Qwen、Doubao\n⚠️ 重要提示 # API 密钥配置：请将 sk-your-api-key 替换为您在 本站 生成的实际 API 密钥\n令牌分组：在 本站 创建令牌时，建议选择 \u0026ldquo;企业分组 官转分组\u0026rdquo;\n网络连接：确保网络连接稳定，工具需要与 API 服务器通信\n项目目录：建议在具体项目目录下使用，以获得更好的上下文理解\n🔧 高级功能 # IDE 集成 - 支持 Cursor 等 IDE 集成\nMCP 服务器 - 扩展 Agent 能力\nCI/CD 集成 - 自动化代码审查流程\n团队规范 - 通过CLAUDE.md文件定义团队规范\n"},{"id":2,"href":"/docs/otherai/sdk/openaisdk/","title":"OpenAI官方SDK","section":"官方SDK类","content":" OpenAI官方SDK ​ # 使用 OpenAI API 查询 GPT-4 # 以下是一个示例代码，演示如何使用 OpenAI API 查询 GPT-4 模型的回答。\n示例代码 ​ # import openai def query_gpt4(question): openai.api_key = \u0026#34;sk-xxx\u0026#34; # 替换为您的 API 密钥 # openai.base_url = url openai.base_url = \u0026#39;https://api.whatai.cc/v1/\u0026#39; # 设置 API 基础 URL try: response = openai.chat.completions.create( model=\u0026#34;gpt-4\u0026#34;, # 确认使用 GPT-4 模型 messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: question} ] ) print(response) # 打印完整的响应 return response[\u0026#39;choices\u0026#39;][0].message[\u0026#39;content\u0026#39;] # 返回 GPT-4 的回答 except Exception as e: return str(e) # 返回错误信息 # 问题 question = \u0026#34;为什么太阳那么红？\u0026#34; # 获取并打印回答 answer = query_gpt4(question) print(answer) 注意事项 ​ # 确保您替换, sk-xxx, 为您的有效 API 密钥。\n使用正确的 API 基础 URL，并根据需要修改其他设置。\n"},{"id":3,"href":"/docs/otherai/tools/raycast/","title":"Raycast 插件 ChatGPT 使用指南（推荐使用）","section":"工具类","content":" Raycast 插件 ChatGPT 使用指南（推荐使用） # 安装插件, 在 Raycast Store 中找到 ChatGPT 插件，并按照提示安装：\n配置 API Key, 安装完成后，在该插件配置中的 API Key 中填入我们的 API Key。选中 Change API Endpoint，并在 API Endpoint 中填入 https://api.whatai.cc/v1。\n🍺 Enjoy it!\n"},{"id":4,"href":"/docs/aidocs/base/","title":"基本概念-令牌（Token）","section":"基础知识","content":" 📖基本概念-令牌（Token） # 1️⃣ 基本概念 # 别称：密钥、key、token\n用于身份验证核心凭证，关联用户账户信息等\n用户可自主管理令牌，支持以下操作\n✅ 新增多个令牌\n✅ 设置单令牌额度上限\n✅ 指定调用渠道分组（如ssvip、default）\n✅ 绑定调用模型权限\n📖 示例格式（非真实token）：\nsk-UEE3xe6AgDeAvlCUQsP0hJSdyaOsNpByoMtb99CC8POogslU\n💻 管理入口：\n👉 神马中转API令牌控制台\n❓ 用户高频疑问解密 # Q：如何获取 Openai Key？ 如何获取 Claude Key？ 如何获取 gemini key？\n→ A：Key就是令牌！这个key可以使用站内支持模型页面介绍的所有模型（260+），GPT系列模型、Claude系列模型、gemini系列模型等等等。\nQ：key为什么不能用？为什么我调用API没反应？\n→ A：大部分情况是 Base url设置不正确造成。需要把Openai的Baseurl改成 https://api.whatai.cc\nQ: 单个key的并发或RPM、TPM有限制吗？\n→ A：: 没有限制。神马中转API不会主动限制用户 RPM TPM ，但所有模型账号都是所有用户共享，遇到使用高峰可能会 429 或 500 报错。高并发需求用户可以寻找客服咨询。\n"},{"id":5,"href":"/docs/ailearn/wallet/","title":"基础教程-钱包 · 页面","section":"站内基础教程","content":" 基础教程-钱包 · 页面 # 💰 我的钱包：您的AI算力加油站 # 余额即能量！ 钱包有余额才能激活令牌（Key），开启AI超能力——就像手机要先充值才能通话📱\n💻 充值入口：\n👉神马中转API钱包\n🎁 新人大礼包 # 注册即送$0.2算力额度 ≈ 免费体验10次深度问答 或 200次短对话！\n🎉 双通道充值系统 # 方式 操作步骤 到账速度 客服支持 兑换码充能 1. 联系客服获取算力额度 2. 钱包页输入兑换码 3. 点击「兑换」按钮 5分钟 ✅ 专属客服对接 闪电充值 1. 进入钱包页 2. 点击「支付宝/微信/USDT」图标 3. 扫码支付完成 秒到账 自动到账 🔋 最低充能：$1起充（≈50次短问答）\n💼 企业尊享服务 # 联系客服解锁特权： ✅ 大额支付（单笔$2000+） ✅ 电子发票（充值后7天内开票） ✅ 对公转账（支持公户付款） 🌟 邀请秘诀 # 邀请3位好友各充30算力额度等于您白赚9算力（足够生成3份商业计划书！）\n"},{"id":6,"href":"/docs/introduction/","title":"神马中转API一站式AI大模型API中转站 · 低价好用稳定的中转API服务","section":"神马中转API 一站式AI大模型API聚合平台 · 行业领先","content":" 神马中转API一站式AI大模型API中转站 · 低价好用稳定的中转API服务 # 神马聚合中转API是一个高效的Open AI、Midjourney API代理、Claude代理、Suno代理等供应商 我们致力于提供优质的 API 接入服务，让您可以轻松集成先进的AI模型至您的产品和服务。通过 API 综合管理平台，无缝整合OpenAl最尖端的人工智能模型。借助我们可靠且易于使用的API解决方案，升级您的产品与服务。\n随着大模型与人工智能应用的普及，越来越多的开发者与企业希望快速集成各类AI接口。然而，直接调用不同厂商的API往往面临接口差异大、计费复杂、访问不稳定等问题。这时候，AI API中转站的价值就凸显出来了。 什么是AI API中转站？ # AI API中转站，顾名思义，就是一个聚合、统一和转发AI接口调用的服务平台。开发者无需分别对接多个厂商的API，只需通过中转站，就能调用不同模型与服务。它相当于“中间层”，帮助开发者屏蔽底层的复杂性，提供更加稳定、高效、灵活的接入方式。\nAI中转站的核心优势 # 1. 统一接口标准 # • 各家大模型（如OpenAI、Anthropic、Google、智谱、月之暗面等）的API参数各不相同，直接调用容易增加学习和维护成本。\n• 中转站将不同接口进行标准化，开发者只需学习一套规范，即可调用多个模型。\n2. 提升访问稳定性 # • 直连官方API可能会受到网络环境、节点延迟或不可用情况影响。\n• 中转站往往部署了全球加速和负载均衡，确保请求更稳定、更顺畅。\n3. 聚合计费与灵活套餐 # • 不同厂商的API价格策略不一，充值也要分别管理。\n• 中转站支持统一计费、统一充值，并且可以提供更灵活的套餐选择，降低使用门槛。\n4. 支持多模型切换 # • 一个项目可能需要不同模型（例如GPT适合文本生成，Claude适合长文档处理，本土模型更适合中文任务）。\n• 中转站可以让你在一条API内快速切换和调用不同模型，极大提升开发效率。\n5. 额外功能与增强服务 # • 一些中转站提供调用日志、使用统计、速率限制优化、故障自动切换等附加功能。\n• 对企业级用户，还可能支持私有化部署与团队协作。 为什么选择【神马聚合中转API】（api.whatai.cc）？ # 在众多中转服务中，神马聚合中转API（api.whatai.cc）凭借稳定性、易用性与性价比脱颖而出：\n• 多模型支持：支持国内外主流大模型，满足不同场景的需求。\n• 高可用性：全球加速+负载均衡，保证请求稳定性与低延迟。\n• 统一调用规范：开发者只需学习一次，即可调用所有支持的AI接口。\n• 灵活计费：按量计费、套餐灵活，避免资金分散在多个平台。\n• 开发者友好：提供完善的文档、调用示例与调试工具，接入成本低。\n适用场景 # • 个人开发者：想要快速体验不同模型，无需注册多个平台。\n• 企业应用：需要在不同业务中调用多个模型，降低运维与成本压力。\n• 创业团队：快速验证产品原型，避免API接入的重复工作。\n主流模型全支持 # 聚合中国和全球300+多模态大模型 文生文、文生图、文生视频、文生音频 神马中转API汇聚了国内外300+多模态大型人工智能模型，全面支持文生文、文生图、文生视频、文生音频等多种模态API。这些模型基于深度学习技术，具备强大的自然语言处理、图像识别、视频分析和音频合成能力，让您的AI应用如虎添翼。核心优势包括海量模型资源、多样化生成能力、智能优化算法和简单易用等。应用场景广泛，包括营销推广、内容创作、教育培训和娱乐互动等。\nOpenAI 顶级大模型 # 全球顶级人工智能AI大模型\nGPT-5\nModel List: GPT-5 gpt-5 GPT-5 gpt-5-mini GPT-4.1 gpt-4.1 GPT-4.1 gpt-4.1-mini o1 \u0026amp; o3 o1 / o3-mini GPT-4 gpt-4o GPT-4 gpt-4o-mini Text-to-Image gpt-image-1 Text-to-Speech whisper-1 \u0026hellip; Anthropic AI大模型 # OpenAI的主要竞争对手，模型能力不输GPT\nClaude 4.1\nModel List: claude-4.1 claude-opus-4-1-20250805 claude-4 claude-sonnet-4-20250514 claude-4 claude-opus-4-20250514 claude-3.7 claude-3-7-sonnet claude-3.5 claude-3-5-sonnet claude-3 claude-3-opus-20240229 claude-3 claude-3-haiku-20240307 claude-3 claude-3-haiku \u0026hellip; 开源大模型 # 主流开源人工智能大模型\nDeepSeek\nModel List: DeepSeek R1 deepseek-reasoner DeepSeek V3 deepseek-chat Llama3.3 llama-3.3-8b-instant Llama3 llama-3-70b code-llama code-llama-34b code-llama code-llama-13b mistral mistral-large-latest mistral mistral-medium-latest \u0026hellip; 如何快速接入神马聚合中转API # ⚡3步闪电接入【神马聚合中转API】（api.whatai.cc） · 智启全球260+顶尖AI · 自由选源 精准控成本\n✅极简通用流程：\n开发者｜企业｜创作者 — 仅需3步，零配置调用 ChatGPT、Claude、Gemini 等 260+ 全球模型！\n支持多源渠道接入 · 价格透明对比 · 按预算自由选择\n✅专属核心价值：\n开发者｜低成本集成 + 灵活选型降本，高效构建AIGC 应用\n企业｜API驱动自动化流程 + 预算可控，智能服务升级\n创作者｜零基础玩转AI 创作全场景 + 丰俭由人选渠道\n让复杂归简 · 让创新加速！\n立即体验：【神马聚合中转API】（api.whatai.cc） 🏁 我们的优势 # 🌟 我们100%采用企业高速渠道，无套路无广告无保留聊天数据\n🌟 性价比最高的稳定三无纯净 API 源头\n🌟 覆盖全球8大地区，包括美国、日本、韩国、英国、新加坡、香港、菲律宾和俄罗斯，共计服务10万+满意客户\n🌟 稳定运行18个月，我们承诺永久优质服务\n♥ 选择我们，就是选择高效与可靠 # ❤ 无需科学上网，全球直连，无封号风险，请求速度是个人账号的1200倍\n❤ 无需模型权限，直接使用最新模型，无需开发基础，一个API key全模型通用\n❤ 完全兼容OpenAI接口协议，支持无缝对接所有模型到各种支持接口的应用\n❤ API key可设定使用时间和余额，便于二次销售 ❤ 100％保障隐私，仅做API中转\n❤ 享受我们的渠道优势，价格远低于官方\n❤ 支持超多模型、各种渠道，价格 \u0026amp; 质量都有保证\n总结 # AI API中转站的出现，大大简化了AI接口的接入与管理成本。通过 神马聚合中转API（api.whatai.cc），开发者和企业能够以更低成本、更高效率、更稳定的方式调用全球主流AI模型，为智能应用的落地加速。\n"},{"id":7,"href":"/docs/openai/syfw/","title":"适用范围：♥ 所有模型","section":"Openai请求格式（通用）","content":" 适用范围：♥ 所有模型 # API 统一请求格式 # 所有模型（包括非OpenAI模型）的请求格式已统一为OpenAI格式。\n功能特点 # 使用OpenAI请求格式可调用所有模型（Claude、Gemini、Doubao、Qwen等）\n支持直接使用OpenAI SDK调用任意模型\n基础信息 # Base URL: https://api.whatai.cc\n认证方式: API Key (替换为******)\nPython示例代码 # import openai # 配置API密钥 openai.api_key = \u0026#34;******\u0026#34; # 替换为你的实际API密钥 openai.api_base = \u0026#34;https://api.whatai.cc\u0026#34; # 设置API基础地址 # 调用示例（以Claude模型为例） response = openai.ChatCompletion.create( model=\u0026#34;claude\u0026#34;, # 指定模型名称 messages=[ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;你好\u0026#34;} ] ) print(response.choices[0].message.content) 注意：实际使用时请将******替换为你的真实API密钥\n"},{"id":8,"href":"/docs/otherai/chat/chatgptwebmidjourneyproxy/","title":"Chatgpt-web-midjourney-proxy","section":"对话客户端类","content":" Chatgpt-web-midjourney-proxy配置教程 # 进入设置\u0026ndash;服务端\u0026ndash;\n填入 API秘钥 和 API地址（https://api.whatai.cc）\n保存\n"},{"id":9,"href":"/docs/otherai/sdk/geminisdk/","title":"Gemini SDK 配置","section":"官方SDK类","content":"#Gemini SDK 配置\n🌟 Gemini Python SDK 入门文档 # 🔧 1. 安装与设置 # 获取 API 密钥 # 在网站 https://api.whatai.cc/token 获取令牌\n🚀 2. 生成简单文本 # CUSTOM_BASE_URL // 网站 BaseURL 通常是域名 API_KEY // 令牌页获取的令牌 非流式\nfrom google import genai from google.genai import types client = genai.Client( http_options=types.HttpOptions( base_url= CUSTOM_BASE_URL ), api_key= API_KEY ) response = client.models.generate_content( model=\u0026#34;gemini-2.5-flash\u0026#34;, contents=\u0026#34;How does AI work?\u0026#34; ) print(response.text) "},{"id":10,"href":"/docs/otherai/devtools/pythonopenai/","title":"python openai官方库（使用AutoGPT，langchain等）","section":"编程工具类","content":" python openai官方库（使用AutoGPT，langchain等） # 方法一\nimport openai openai.api_base = \u0026#34;https://api.whatai.cc/v1\u0026#34; 方法二（方法一不起作用用这个）\n修改环境变量OPENAI_API_BASE，各个系统怎么改环境变量请自行搜索，修改环境变量后不起作用请重启系统。\nOPENAI_API_BASE=https://api.whatai.cc/v1 "},{"id":11,"href":"/docs/ailearn/model/","title":"基础教程-支持模型 · 页面","section":"站内基础教程","content":" 基础教程-支持模型 · 页面 # "},{"id":12,"href":"/docs/openai/ptdhfl/","title":"普通文本对话（非流）","section":"Openai请求格式（通用）","content":" 普通文本对话（非流） # 基础信息 # 接口地址: https://api.whatai.cc\n认证方式: Bearer Token (API Key)\n普通对话接口 # POST 请求示例\nimport requests import json # 配置API参数 url = \u0026#34;https://api.whatai.cc/v1/chat/completions\u0026#34; # API端点 payload = { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, # 指定模型 \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;周树人和鲁迅是兄弟吗？\u0026#34; } ] } headers = { \u0026#39;Accept\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;sk-******\u0026#39;, # 替换为你的API Key \u0026#39;User-Agent\u0026#39;: \u0026#39;xxx/1.0.0\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; } # 发送请求 response = requests.post(url, headers=headers, data=json.dumps(payload)) print(response.text) 使用OpenAI官方SDK # from openai import OpenAI # 初始化客户端 client = OpenAI( api_key=\u0026#34;sk-******\u0026#34;, # 替换为你的API Key base_url=\u0026#34;https://api.whatai.cc/v1\u0026#34; # API中转地址 ) # 创建对话 chat_completion = client.chat.completions.create( messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;周树人和鲁迅是兄弟吗？\u0026#34;, } ], model=\u0026#34;o1\u0026#34;, # 指定模型 ) print(chat_completion) 注意事项 # 请妥善保管API Key，不要泄露\n所有请求必须通过HTTPS发送\n响应格式为JSON\n"},{"id":13,"href":"/docs/aidocs/key/","title":"添加令牌：您的AI通行证指南","section":"基础知识","content":" 🔑 添加令牌：您的AI通行证指南 # 一Key在手，AI我有！ 令牌（API Key）是解锁AI能力的数字钥匙，就像手机SIM卡激活网络\n⚠️ 安全警示：\nKey泄露 = 家门大开！ → 立即删除并重建\n🔐 密钥格式：sk-xxxxxxxx（默认隐藏，可点击右边按钮复制）\n💻 操作入口\n👉 神马中转API令牌控制台\n📄 配置项说明 # 🔖1. 令牌名称 # 自定义标识符（建议按用途命名，如\u0026quot;生产环境API\u0026quot;） ⏳ 2. 过期时间 # 设置令牌的有效期间，超过则该令牌无法使用 💰 3. 额度 # 配置当前令牌的可使用额度\n选项 可用额度规则 ✅ 无限额度 动态关联主账户余额，可用额度 = 钱包实时余额 🔄 自定义额度 设定固定当前令牌的消费上限 **若设置值 \u0026gt; 钱包余额时：**实际额度 = 钱包余额 🔢4. 创建数量 # 默认为1\n当您输入数量值 N（如2），系统将创建N（2）个相同（当前）配置项的令牌\n🌐5. 令牌渠道分组 # 🎯 渠道分组配置 # [配置作用]\n来源差异化：不同分组对应不同来源，稳定性高选高价分组，不介意稳定性则可以选择低价分组\n价格差异化：不同分组对应不同计费标准\n消费隔离：将高/低成本业务分流到不同分组\n预算优化：为测试/生产环境令牌配置不同成本分组\n例：开发令牌配置低成本组，生产令牌配置高稳定性组\n⚠️ 注意：请在****页面查看，根据自己实际情况进行配置 [配置规则]\n支持多选分组\n优先级排序规则：\n• 位置越靠前优先级越高\n• 同模型存在多组时 → 优先使用排序第一的组\n[示例]\n分组排序：[default, claude官, origin] → 调用共用模型时优先使用default组渠道\n⚙️自动选择分组机制 # [工作逻辑]\n✅ 开启时：\n系统检测调用模型所属分组\n若模型不在令牌分组中 → 自动重定向到模型默认组\n例：模型a仅在ssvip中有，但是上面渠道分组配置只选了vip组 → 调用模型a时，自动使用ssvip组渠道\n❌ 关闭时：\n调用模型不在令牌分组 → 直接返回403错误\n⚠️ 注意：默认开启，若不需要，需要勾选关闭自动选择分组选项\n🔧6. 模型限制 # ✅ 默认关闭：令牌可访问平台所有模型\n启用时：仅限访问明确指定的模型\n【示例】该令牌只能调用c-3-sonnet、flux-chat模型\n🔧7. 对话模型设置（可配置可不配置） # 1️⃣ 启用图片请求格式整理**(可选)**\n作用：自动修复不规范的识图请求格式（如多图拼接错误、参数缺失等）。\n建议：仅当出现图片识别失败时开启，正常情况无需启用。\n2️⃣ 启用图片链接转 base64 再传递**(可选)**\n作用：将大陆无法访问的图片链接转为Base64编码传递，解决官方接口屏蔽问题。\n注意：会延长响应时间300-800ms，非大陆用户不建议开启。\n3️⃣ 设置推理模型 Reason 内容的位置**(可选)**\n作用：手动指定模型返回推理内容（Reason）的字段位置。\n注意：默认会根据模型返回内容设置，推理内容可能在 Think 、 reason_content 中\n💡 8.模型重定向（可选） # 作用：魔法级请求变身术！ # 自动把请求中的 模型A 变成 模型B，完美解决：\n1️⃣ 老客户端卡在旧模型 → 🤖 原地升级新模型\n2️⃣ 客户端锁死模型 → 🔓 绕过限制器\n3️⃣ 模型突然下架 → 急救重定向\n⚙️ 配置规则： # [输入框1] 客户请求的模型名（伪装名）[输入框2] 真实调用的模型名（替身演员）【示例】客户端请求gpt-3.5，服务器真实调用gpt-4-turbo\n🔒 IP白名单（安全锁） # 启用后 → 只有白名单IP能通行\n其他IP访问？直接吃闭门羹！ 🚫\n【输入框】 填写你的 IP 或IP段（一个逗号一个） 【示例】： 114.214.186.111,182.168.1.0/24\n💥 使用场景\n▸ 企业服务器固定IP → 🤖 禁止员工摸鱼\n▸ 只允许自家APP调用 → 📱 封杀第三方工具\n▸ 金融级安全防护 → 💰 防API密钥泄露\n✅ 救命锦囊：\n先添加当前IP（防自锁）\n公司IP用/24网段覆盖\n开小号令牌做备用钥匙 🔑\n🌟 终极安全套餐：\n【IP白名单】 + 【模型限制】 + 【用量监控】= 黑客看了连夜删号跑路 👻\n⚠️****预警额度 # 设置当前令牌的额度红线 → 自动提醒🔔\n📌 必看重点\n1️⃣ 先到个人中心→消息订阅开启通知❗\n▸ 没订阅=哑炮预警🤫\n【示例】当前令牌剩余算力额度到达 10时提醒\n🚦 限流器（可选） # 当用户 XXX秒内狂点 XXX次 → 直接发射 冷静导弹 💥\n（自动弹出提示 + 强制冷静期 ❄️）\n【示例】当前用户10秒请求该令牌50次，提示你让服务器裂开了！\n🔥 经典套餐\n防刷场景 推荐配置 死亡提示 防脚本爆破 5秒10次 \u0026ldquo;人类，你太快了！\u0026rdquo; 🤖 保护GPT-4钱包 60秒3次 \u0026ldquo;手慢点！烧的是钱啊！\u0026rdquo; 💸 🎨 MJ绘图模式 # 给每个令牌绑定独立绘图策略\n令牌纬度控制 Midjouney 配置，设置优先级：令牌 \u0026gt; 路径参数 \u0026gt; 系统默认\n🌐 MJ图片代理方案（速度救星） # 控制在 Fetch、回调中的图片地址(image_url)\n选项 效果 总结 系统默认 随缘加载，可能转圈到崩溃 🌀 🐢💔 (龟速心碎) (origin) Discord （直连源地址） 国外很快，国内无法访问 🌏❌ (地球打叉) (proxy) 图片代理地址 国外很慢，国内可以访问 🌏❌ (地球打叉) 自定义图片代理 自建高速通道，爽到起飞 🚀✨ (火箭喷发) 令牌纬度控制 Midjouney 配置，设置优先级：令牌 \u0026gt; 路径参数 \u0026gt; 系统默认\n⚠️ 异步任务 · 关闭资源代理 # 🚫 高危操作警告\n关闭此开关 = 亲手拆除安全气囊 🛡️💥\n系统将不再自动修复以下问题： 国内访问 Discord 必失败的墙问题 🧱\n浏览器跨域拦截(CORS) ❌\n需要自行解决\n"},{"id":14,"href":"/docs/otherai/tools/dify/","title":"Dify","section":"工具类","content":" 接入到Dify # 1.使用OpenAI模型 # 点击右上角自己的头像，点击设置\n点击模型供应商，选择OpenAI的设置\n输入神马中转API 后台-使用API-API Keys 生成的API KEY，输入API Base：https://api.whatai.cc/v1/chat/completions，点击保存即可\n2. 使用其他模型 # 下拉找到OpenAI-API-compatible，选择添加模型\n模型名称填写你想要使用的模型，准确的名称可以通过 模型价格页面 查看\n输入神马中转AI 后台-使用API-API Keys 生成的API KEY，输入API Base：https://api.whatai.cc/v1/chat/completions，点击保存即可\n"},{"id":15,"href":"/docs/otherai/chat/lobechat/","title":"Lobe-Chat","section":"对话客户端类","content":" Lobe-Chat ​配置教程 # 将接口代理地址改成API地址的链接：https://api.whatai.cc\n"},{"id":16,"href":"/docs/otherai/devtools/codegpt/","title":"VSCode 插件 Code GPT 使用指南","section":"编程工具类","content":" VSCode 插件 Code GPT 使用指南 # 这个插件修改 Host 相对麻烦一些，需要修改源码才可以使用。以下是详细的步骤：\n步骤 # 这个插件修改Host相对麻烦一些，需要修改源码才可以使用。\n安装插件。安装好后按Ctrl+Shift+P，弹出框中输入Open Extensions Floder 点击Extensions: Open Extensions Floder，这将打开插件目录，找到Code GPT的文件夹。 打开后进入打开文件./src/clients/openai_client.js，搜索文件中的api.openai.com，并替换为 api.whatai.cc。保存文件。 再次回到vscode，按Ctrl+Shift+P，弹出框中输入CodeGPT: Set API KEY，点击CodeGPT: Set API KEY。然后将购买的Key输入进去即可。 以上步骤完成后，重启VSCode 其他VSCode插件类似。 "},{"id":17,"href":"/docs/aidocs/api/","title":"基本概念-API地址（BaseURL）","section":"基础知识","content":" 📖基本概念-API地址（BaseURL） # 1️⃣ 基本概念 # 中转网址，用于替换官方API地址\n官方地址：https://api.openai.com 需要被替换成 神马中转API地址：https://api.whatai.cc\n所有地址数据互通\n💻 API（BaseUrl）信息入口： # 👉 神马中转API工作台\n根据自己调用API的地理位置选择最优线路以获得最佳体验\n部分路线可能区域网络受限，若无法正常访问API地址，请尝试更换地址\n🔌 完整功能接口映射表 # 功能 路径 完整示例URL 智能对话 /v1/chat/completions https://api.whatai.cc/v1/chat/completions 文本嵌入 /v1/embeddings https://api.whatai.cc/v1/embeddings AI绘图 /v1/images/generations https://api.whatai.cc/v1/images/generations 语音转文本 /v1/audio/transcriptions https://api.whatai.cc/v1/audio/transcriptions 文本转语音 /v1/audio/speech https://api.whatai.cc/v1/audio/speech 在 claude code 里只需要配置域名，不需要带 /v1及后面的部分。\nPython 示例\n需要先 pip install openai\nimport openai # 配置API密钥和基础URL openai.api_key = \u0026#34;sk-******\u0026#34; # 替换为你的实际令牌 openai.api_base = \u0026#34;https://api.whatai.cc\u0026#34; # 设置中转地址# 调用对话接口示例 response = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;你好\u0026#34;}] ) print(response.choices[0].message.content) curl 示例 # curl --request POST \\ --url https://api.whatai.cc/v1/chat/completions \\ --header \u0026#39;Authorization: Bearer sk-替换为你的key\u0026#39; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ --data \u0026#39;{ \u0026#34;max_tokens\u0026#34;: 8192, \u0026#34;model\u0026#34;: \u0026#34;gpt-4.1-mini\u0026#34;, \u0026#34;temperature\u0026#34;: 0.8, \u0026#34;top_p\u0026#34;: 1, \u0026#34;presence_penalty\u0026#34;: 1, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;你是我的全能助手，你叫小美\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;你是谁？夸我几句我就给你续费~\u0026#34; } ] }\u0026#39; "},{"id":18,"href":"/docs/ailearn/chat/","title":"基础教程-聊天 · 页面","section":"站内基础教程","content":" 基础教程-聊天 · 页面 # ⚡ 双通道配置聊天 ​ # ⚠️ 请先创建令牌，才可使用站内聊天\n💻 管理入口**👉**令牌控制台 📖令牌配置指南👉 基础知识-基本概念-添加令牌(填写项解析)\n🚀 方式一：闪电直连（推荐） # 在令牌列表找到目标Key\n点击「聊天」按钮\n系统自动完成：\n注入Key到聊天窗\n配置BASE_URL\n选择默认模型\n💡 适合场景：快速体验、临时调试\n🛠️ 方式二：手动配置（高级） # Step 1 进入聊天页面 → 设置 ⚙️ → 服务端\nStep 2 填写关键参数：\n必备参数： API Key(令牌) ███ sk-xxxxxxxxxxxx （粘贴复制的Key） BaseURL ███ 选填以下任一： https://api.whatai.cc https://api.whatai.cc/v1 https://api.whatai.cc/v1/chat/completions Midjourney专用地址： https://api.whatai.cc https://api.whatai.cc/mj BaseURL指南：基础知识-基础概念-API地址（BaseURL） Step 3 填写模型：\n访问「支持模型」页面\n复制目标模型名称（如 gpt-4-turbo）\n在聊天窗口粘贴到模型选择框\n4.点击保存\nStep 4 回到聊天页面，可以开始聊天啦！！！！！！！\n"},{"id":19,"href":"/docs/openai/ptdhls/","title":"普通文本对话（流式输出）","section":"Openai请求格式（通用）","content":" 普通文本对话（流式输出） # 基础信息 # 接口地址: https://api.whatai.cc\n认证方式: Bearer Token (API Key)\n请求参数 # 参数 类型 说明 model string 模型名称(如gpt-4o-mini) stream boolean 是否开启流式输出 messages array 对话消息列表 Python 请求示例 # import json import requests # 配置请求参数 url = \u0026#34;https://api.whatai.cc/v1/chat/completions\u0026#34; headers = { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer sk-******\u0026#34;, # 替换为你的API Key \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } payload = { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;stream\u0026#34;: True, # 开启流式输出 \u0026#34;messages\u0026#34;: [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;周树人和鲁迅是兄弟吗？\u0026#34;}, ] } # 发送请求并处理流式响应 response = requests.post(url, headers=headers, json=payload, stream=True) buffer = \u0026#34;\u0026#34; for chunk in response.iter_content(chunk_size=None): if chunk: buffer += chunk.decode(\u0026#34;utf-8\u0026#34;) while \u0026#34;\\n\u0026#34; in buffer: line, buffer = buffer.split(\u0026#34;\\n\u0026#34;, 1) if not line.strip(): # 跳过空行 continue if line.startswith(\u0026#34;data: \u0026#34;): data_line = line[6:].strip() # 去除\u0026#34;data: \u0026#34;前缀 if data_line == \u0026#34;[DONE]\u0026#34;: # 流式结束标记 break try: data = json.loads(data_line) # 提取并打印响应内容 content = data[\u0026#34;choices\u0026#34;][0][\u0026#34;delta\u0026#34;].get(\u0026#34;content\u0026#34;, \u0026#34;\u0026#34;) print(content, end=\u0026#34;\u0026#34;, flush=True) except json.JSONDecodeError: # 处理不完整JSON数据 buffer = line + \u0026#34;\\n\u0026#34; + buffer break 注意事项 # 请妥善保管API Key\n建议使用HTTPS协议\n响应格式为JSON\n"},{"id":20,"href":"/docs/otherai/devtools/easycode/","title":"JetBrains插件 Easycode ​","section":"编程工具类","content":" Jetbrains插件ChatGPT - Easycode # 安装好插件后在Settings \u0026gt; Tools \u0026gt; OpenAI \u0026gt; GPT 3.5 Turbo中如图所示配置好插件，重点要将Server Settings 修改为 https://api.whatai.cc/v1/chat/completions 。并勾选Customize Server。\n"},{"id":21,"href":"/docs/otherai/chat/utools-chatgpt/","title":"utools-ChatGPT","section":"对话客户端类","content":" utools-ChatGPT ​配置教程 # "},{"id":22,"href":"/docs/openai/gdgshscjson/","title":"固定格式化输出Json","section":"Openai请求格式（通用）","content":" 固定格式化输出Json # 格式化输出 接口说明 # 通过OpenAI API获取产品信息，返回JSON格式数据。\n请求地址 # POST https://api.whatai.cc/v1/chat/completions\n请求参数 # Headers # 参数名 类型 必填 说明 Authorization string 是 API密钥，格式: Bearer ****** Content-Type string 是 固定值: application/json Body # { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-2024-08-06\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;根据给出的产品进行分析，按json格式用中文回答,json format:product_name, price, description.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;产品描述\u0026#34; } ], \u0026#34;response_format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34; } } Python示例代码 # from pydantic import BaseModel from openai import OpenAI from dotenv import load_dotenv import json from textwrap import dedent # 加载环境变量，例如 API key 等配置信息 load_dotenv() # 设置 OpenAI API 的工厂名称，默认为 \u0026#34;openai\u0026#34; factory = \u0026#34;openai\u0026#34; # 初始化 OpenAI 客户端，传入 API key 和 base URL client = OpenAI( api_key=\u0026#34;sk-***********************************************\u0026#34;, # 替换为你的 API key base_url=\u0026#34;https://api.whatai.cc/v1/\u0026#34; # 这里是 base url，注意这里需要 /v1/ ) # 定义一个产品信息类，用于解析 API 返回的数据 class ProductInfo(BaseModel): product_name: str # 产品名称，字符串类型 price: float # 价格，浮点数类型 description: str # 产品描述，字符串类型 # 定义一个提示信息，用于请求模型返回 JSON 格式的产品信息 product_prompt = \u0026#39;\u0026#39;\u0026#39;根据给出的产品进行分析，按json格式用中文回答,json format:product_name, price, description.\u0026#39;\u0026#39;\u0026#39; # 获取产品信息的函数，传入用户的问题 def get_product_info(question: str): # 使用 OpenAI 客户端进行聊天模型的请求 completion = client.beta.chat.completions.parse( model=\u0026#34;gpt-4o-2024-08-06\u0026#34;, # 指定使用的模型 messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: dedent(product_prompt)}, # 发送系统消息，设置模型的行为 {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: question}, # 发送用户消息，用户提出问题 ], response_format=ProductInfo, # 指定返回的数据格式为 ProductInfo ) # 返回模型解析的第一个选项的消息结果 return completion.choices[0].message.parsed # 初始化一个空的产品信息字典 product_inform = {} # 定义将解析的结果转换为 JSON 的函数 def transform2JSON(parsed_result): # print(parsed_result) # 打印解析结果 # 将解析的结果存储到字典中 product_inform[\u0026#34;product_name\u0026#34;] = parsed_result.product_name product_inform[\u0026#34;price\u0026#34;] = parsed_result.price product_inform[\u0026#34;description\u0026#34;] = parsed_result.description # 将字典转换为 JSON 字符串并返回，ensure_ascii=False 允许中文字符正常显示 return json.dumps(product_inform, ensure_ascii=False, indent=4) # 定义用户输入的问题，即一个产品信息的描述 question = \u0026#34;75寸小米电视机\u0026#34; # 调用函数获取产品信息 result = get_product_info(question) # 将解析结果转换为 JSON 格式并打印 json_result = transform2JSON(result) print(json_result) 返回示例 # { \u0026#34;product_name\u0026#34;: \u0026#34;小米电视75寸\u0026#34;, \u0026#34;price\u0026#34;: 4999.0, \u0026#34;description\u0026#34;: \u0026#34;4K超高清画质，支持HDR，内置小爱同学语音助手\u0026#34; } 注意事项 # 请妥善保管API密钥\n产品信息由AI生成，仅供参考\n"},{"id":23,"href":"/docs/aidocs/group/","title":"基本概念-令牌渠道分组","section":"基础知识","content":" 📖 基本概念-令牌渠道分组 # 1️⃣ 基本概念 # 别称：分组、渠道、渠道分组、API分组\n区分模型的渠道来源和对应的价格\n价格透明**·**用户可以根据自己的需求，选择最适合自己的分组。\n⚠️ 不同分组只是个别模型价格不一样，不是所有模型都会价格不一样。\n使用方式： 在令牌页面→新增/编辑令牌时，选择对应的渠道分组即可\n🌲 渠道分组使用教程：\n💻 模型分组详情查看入口：\n💰 官方费率解析 # 当官方费率 = 1 时，网站上1算力额度等价于对应的模型官方价格的 1$。\n当官方费率 = 2 时，网站上1算力额度等价于对应的模型官方价格的 0.5 $。\n📊 API分组游乐场（选对分组，效果翻倍！） # 分组名 渠道来源 必杀技 适合人群标签 **默认分组（deafult）****·**万能工具包 GPT+Claude混合 全能模型全覆盖 想一次性试用所有模型的新手玩家 claude官**·**特供快线 Claude官方 官方特价（偶尔排队） 想薅Claude羊毛的精明党 openai官-优质**·**超跑VIP赛道 OpenAI纯净 o1/realtime加速 🚀速度狂魔·科技发烧友 origin**·**头等舱服务 官方原价 ✨ 企业级稳定性（稳定性堆到满级，不差钱！） 💼土豪公司/拒绝翻车的严苛需求 AZ-优质**·**性价比之王 Azure纯净 o1/o3加速 ️性能与预算平衡大师 svip**·**省钱宝 极致低价 💰预算敏感型 vvip**·**长文本刺客 OpenAI逆向 大段文字优惠 📜论文党·小说作家 vip**·**用量忍者 按量付费越用越便宜 📊灵活用量派 claude**·**逆神秘通道 Claude逆向 Cursor专属优惠 🤫逆向探索家 国产特价**·**清仓大促 国产模型 骨折价限时供应手慢无 🛒捡漏王·短期项目党 gemini优质**·**视频解说员 Gemini Pro 支持视频解析🎥 🎬短视频创作者·多媒体控 ✨ 分组选择攻略： # 要速度 → 选「超跑VIP赛道」(openai官-优质)\n要省钱 → 蹲「特价独享通道」(claude官)\n要稳定 → 砸钱上「头等舱」(origin)\n玩长文 → 认准「长文本刺客」(vvip)\n💡 比喻总结：默认分组=共享单车 | 特价分组=打折高铁 | 企业分组=私人飞机就像选交通工具——根据你的预算和目的地，挑最对的那辆！\n✨ 渠道来源说明（看不懂的话可忽略）： # 渠道来源 技术本质 超能力✨ 小缺陷⚠️ 最适合谁 逆向 OpenAI官网逆向 🧠 官网同款智商 💰 价格优惠 🔒 非官方接口 预算有限的聪明玩家 按次混合 逆向+Azure双引擎 ⚡️ 双重加速 💸 用多少次付多少 🔒 非官方接口 用量不固定的灵活派 Azure 微软官方通道 支持100w并发 🛠️ FC/TC全功能 偶尔降速 🔍 有内容审核 企业正规军 企业无审核 无审核Azure+OpenAI兜底 🌪️ 1000w超高并发 🗽 畅所欲言无审核 ⚡ 双引擎护航 ⛈️ 偶尔天气干扰 土豪公司/敏感内容需求 纯官方 官方直连 ✨ 官网原生体验 🌪️ 1000w超高并发 ⚡ 极速响应 🌐 受官网波动影响 极致体验追求者 ✨ 模型不同渠道不同分组说明（看不懂的话可忽略）： # 类型 逆向 按次计费（混合） Azure 企业无审核 纯官方（现在默认分组） GPT-4 逆向，全部支持 逆向，全部支持 Azure，全部支持 全部支持 OpenAl，全部支持 GPT-3.5 逆向，全部支持 逆向，全部支持 Azure，全部支持 全部支持 OpenAl，全部支持 GPTs. All 全部支持，按 token计费 全部支持，按次计费 全部支持 全部支持 全部支持 OpenAI 其他 基础模型 全部支持 全部支持 全部支持 全部支持 Midjourney 全部支持 全部支持 全部支持 全部支持 全部支持 国产模型 全部支持 全部支持 全部支持 全部支持 全部支持 Claude 逆向，全部支持 逆向，全部支持 纯 AWS Claude，全部支持 纯 Claude 官方，全部支持 纯 Claude 官方，全部支持 其他模型 全部支持 全部支持 全部支持 全部支持 全部支持 tools call. function call 不支持 不支持 全部支持 全部支持 全部支持 类型 逆向 按次计费（混合） Azure 企业无审核 纯官方（现在默认分组） 分组 vip vvip svip default ssvip 4.0系列 (包含32k、Dalle3) 官方费率 * 0.8 0.1$ 一次 官方费率 官方费率 * 2 官方费率 * 2.5 3.5系列 官方费率 * 0.2 0.005$ 一次 官方费率 官方费率 * 2 官方费率 * 2.5 Claude 逆向 Anthropic Claude Google/AWS Claude Google/AWS Claude Anthropic Claude Gemini 普号号池（便宜，不支持高并发） 普号号池（便宜，不支持高并发） 普号号池（便宜，不支持高并发） 普号号池（便宜，不支持高并发） 官方付费版（支持高并发） Luma API 0.3$ 一次，不可商用 0.3$ 一次，不可商用 0.6$ 一次，可商用，排队优先 0.6$ 一次，可商用，排队优先 0.6$ 一次，可商用，排队优先 其他模型 所有分组统一 所有分组统一 所有分组统一 所有分组统一 所有分组统一 "},{"id":24,"href":"/docs/ailearn/dev/","title":"基础教程-开发者 · 快速接入","section":"站内基础教程","content":" 基础教程-开发者 · 快速接入 # 基础信息 # Base URL: https://api.whatai.cc\n认证方式: Bearer Token (API Key)\n更多baseURL👉： 基础概念-API地址（BaseUrl）\n文本对话接口 # 请求\n方法: POST\n路径: /v1/chat/completions\nHeaders:\nAccept: application/json\nAuthorization: Bearer sk-****** (你的API Key)\nUser-Agent: DMXAPI/1.0.0 (https://api.whatai.cc)\nContent-Type: application/json\n请求参数 # { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;周树人和鲁迅是兄弟吗？\u0026#34; } ] } cURL 示例 # curl -X POST \u0026#34;https://api.whatai.cc/v1/chat/completions\u0026#34; \\ -H \u0026#34;Accept: application/json\u0026#34; \\ -H \u0026#34;Authorization: Bearer sk-******\u0026#34; \\ # 替换为你的API Key -H \u0026#34;User-Agent: DMXAPI/1.0.0\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;周树人和鲁迅是兄弟吗？\u0026#34; } ] }\u0026#39; Python 示例 # import requests import json # API配置 url = \u0026#34;https://api.whatai.cc/v1/chat/completions\u0026#34; headers = { \u0026#39;Accept\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Bearer sk-******\u0026#39;, # 替换为你的API Key \u0026#39;User-Agent\u0026#39;: \u0026#39;DMXAPI/1.0.0\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; } # 请求数据 payload = json.dumps({ \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;周树人和鲁迅是兄弟吗？\u0026#34; } ] }) # 发送请求 response = requests.post(url, headers=headers, data=payload) # 输出响应 print(response.text) 响应 # 返回JSON格式的对话结果\n提示：将示例中的sk-******替换为你实际的API Key即可使用\n"},{"id":25,"href":"/docs/openai/embedding/","title":"embedding代码例子","section":"Openai请求格式（通用）","content":" embedding代码例子 # 基本概念 # 什么是Embedding？ # Embedding（嵌入）是将离散数据（如单词、句子）映射到连续向量空间的技术。通过Embedding：\n语义相似的文本在向量空间中距离更近\n便于机器学习模型处理文本数据\n典型应用：搜索、推荐、分类等场景\n常见Embedding模型 # text-embedding-3-small Openai主流emb模型\ntext-embedding-3-large\ntext-embedding-ada-002\n技术特点 # 特性 说明 维度 通常为数百到数千维（如1024维） 归一化 多数Embedding会做L2归一化 距离度量 常用余弦相似度计算向量距离 多语言支持 现代模型通常支持多语言嵌入 请求地址 # POST https://api.whatai.cc/v1/embeddings\n认证方式 # 需要在请求头中添加 API Key：\nheaders = { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer sk-******\u0026#34;, # 替换为你的API令牌 \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } 请求参数 # 参数名 类型 必填 说明 input string/array 是 单条文本或文本列表 model string 是 使用的模型名称 encoding_format string 否 返回格式（float/base64） 请求示例 # import openai # 设置OpenAI API密钥和基础URL openai.api_key = \u0026#34;sk-***********************************************\u0026#34; # 替换为你的 key openai.base_url = \u0026#34;https://api.whatai.cc/v1/\u0026#34; # 这里是API的 base url，注意这里v1后面需要/，最后的 / 很容易漏掉。 def get_embedding(text): response = openai.embeddings.create( model=\u0026#34;text-embedding-3-small\u0026#34;, input=text ) return response.data[0].embedding # 示例文本 text = \u0026#34;这是一个示例文本,用于演示如何获取文本嵌入。\u0026#34; # 获取文本嵌入 embedding = get_embedding(text) print(f\u0026#34;文本: {text}\u0026#34;) print(f\u0026#34;嵌入向量维度: {len(embedding)}\u0026#34;) print(f\u0026#34;嵌入向量前5个元素: {embedding[:5]}\u0026#34;) 典型应用场景 # 语义搜索：通过向量相似度匹配查询和文档\n聚类分析：将相似文本自动归类\n推荐系统：寻找内容相似的物品\n异常检测：识别语义异常的文本\n性能优化建议 # 批量处理文本（最多支持2048 tokens/请求）\n对静态内容缓存嵌入结果\n使用近似最近邻(ANN)算法加速搜索\n响应示例 # 成功响应(200):\n{ \u0026#34;object\u0026#34;: \u0026#34;list\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;object\u0026#34;: \u0026#34;embedding\u0026#34;, \u0026#34;embedding\u0026#34;: [0.1, -0.2, 0.3, ...], \u0026#34;index\u0026#34;: 0 } ], \u0026#34;model\u0026#34;: \u0026#34;text-embedding-ada-002\u0026#34;, \u0026#34;usage\u0026#34;: { \u0026#34;prompt_tokens\u0026#34;: 5, \u0026#34;total_tokens\u0026#34;: 5 } } 错误响应:\n{ \u0026#34;error\u0026#34;: { \u0026#34;message\u0026#34;: \u0026#34;Invalid input text\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;invalid_request_error\u0026#34; } } "},{"id":26,"href":"/docs/otherai/devtools/langchain/","title":"LangChain​","section":"编程工具类","content":" LangChain # 注意事项 ​ # openai_api_base, 的末尾要加上, /v1/chat/completions, ，而且目前只支持 Chat 模型，请确认不要导入错误的包。 示例代码 ​ # from langchain.chat_models import ChatOpenAI llm = ChatOpenAI( openai_api_base=\u0026#34;https://api.whatai.cc/v1/chat/completions\u0026#34;, openai_api_key=\u0026#34;sk-xxxxx\u0026#34;, ) res = llm.predict(\u0026#34;hello\u0026#34;) print(res) "},{"id":27,"href":"/docs/ailearn/sdk/","title":"高级功能-官方SDK支持","section":"站内基础教程","content":" 高级功能-官方SDK支持 # 支持的厂商 # OpenAI SDK\nAnthropic Claude SDK\nGoogle Gemini SDK\n配置方法 # 只需修改 SDK 的 Key 和 Base Url 即可使用\n# 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;sk-********************************\u0026#34;, # 替换为你的神马中转api 令牌key base_url=\u0026#34;https://api.whatai.cc/v1\u0026#34;, # 使用 神马中转API 中转地址 ) # 示例调用 response = client.chat.completions.create( model=\u0026#34;gpt-4.1-mini\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hello!\u0026#34;}] ) print(response.choices[0].message.content) 提示：将 ****** 替换为你实际的 API Key，其他厂商 SDK 配置方式类似\n"},{"id":28,"href":"/docs/aidocs/pay1/","title":"基本概念-按量付费","section":"基础知识","content":" 📖 基本概念-按量付费 # 💸 按量计费：像交水电费一样简单！ # 用多少字，付多少钱！ 就像家里用电——开灯时间越长，电费越多～\n计费示例 ​ # 文字类模型的计费通常是按照 tokens 计算。\n例如，1K tokens 消耗 xx 美金，这种计费方式与官方渠道相同。\n优惠政策 ​ # 官方渠道的美金购买需要实时汇率（大约 1:7）。\n在我们平台，您可以直接以折扣价格购买美金。\n具体汇率请查询充值页。\n🌰 实景案例 # 【示例】对于default分组下的gpt-4o-mini模型，假设提问文字数量为6323 tokens，文字输出数量为2481 tokens\nInput（提示token数）：0.15/M tokens （您提问的文字） Output（补全token数）: 0.6/M tokens （AI回答的文字） Cache（模型倍率）：0.075 计算方式为： $0.15 / 1000000 * 6323 + 0.6 / 1000000 * 2481 + 0.075/1000000 * 2048 = 0.002284$\n📊 模型倍率（看不懂可以忽略） # 支持价格页面的模型价格即实价！\n倍率不是额外收费，而是定价的「基因公式」——就像咖啡店的菜单，拿铁价格= (咖啡豆成本×倍率)，您看到的已是最终价 ✅\n倍率运作原理（三步透明机制） # ⚠️ 下面只是举例子不是实际定价 # 第一步：设定基础价（全球标准） 例如：GPT-4 基础价 = $0.03/千字（输入） # 第二步：乘以模型倍率（难度系数） 例如：倍率设置 1.5 倍 → $0.03 × 1.5 = $0.045# 第三步：生成最终标价（您看到的数字） 菜单直接显示：GPT-4 输入 → $0.045/千字 消耗时直接按此计算，无隐藏乘除\n❓ 用户高频疑问解密 # Q：倍率会在日志中单独显示吗？\n→ A：不会！您的消费记录只显示 最终标价 × 用量（如：$0.045 × 50,000字）\nQ：为什么不同模型倍率不同？\n→ A：就像不同车型油耗不同\n文本模型 = 经济轿车（倍率1.0）\n多模态模型 = 越野车（倍率2.0，动力更强）\n高速模型 = 跑车（倍率1.5，为速度付费）\nQ：如何知道某个模型的倍率？\n→ A：在模型价格页面勾选倍率即可\n"},{"id":29,"href":"/docs/otherai/chat/sidebar/","title":"浏览器插件 ChatGPT Sidebar","section":"对话客户端类","content":" 浏览器插件 ChatGPT Sidebar ​配置教程 # 步骤 ​ # 官方链接:https://chatgpt-sidebar.com\n安装插件 修改设置, 将 URL 修改为 https://api.whatai.cc\n"},{"id":30,"href":"/docs/otherai/chat/chatbox/","title":"ChatBox(推荐使用)","section":"对话客户端类","content":" ChatBox(推荐使用) ​配置教程 # ChatGPT开源桌面应用，支持全部桌面平台。\n下载链接：https://github.com/Bin-Huang/chatbox/releases\n使用方法：如图在设置中填入购买的密钥，并将代理设置为https://api.whatai.cc即可\n"},{"id":31,"href":"/docs/errorcode/","title":"常见错误以及解决办法","section":"神马中转API 一站式AI大模型API聚合平台 · 行业领先","content":" 常见错误以及解决办法 ​ # Q：切换到了 GPT-4，询问它是不是 GPT-4，为什么回答不是？ ​ # A： 首先，如果你问 GPT-4：“你是不是 GPT-4？”它大概率会回答：“我是 OpenAI 的 GPT-3 模型，目前还没有 GPT-4。”之所以会这样，是因为 OpenAI 开放给 API 调用的 GPT-4，训练数据都是 2021 年 9 月之前的。模型训练好之后，如果不重新训练，并不会自动更新里面的知识，这就好像我问 2021 年的你 2023 年第一顿饭你吃了什么，答案一定是错的。\nQ：为什么 ChatGPT Plus 的 GPT-4 能回答出自己是 GPT-4？ ​ # A： 简单来说，ChatGPT Plus 使用的模型版本和开放给 API 的并不一样，作为内部版本，很大可能会用更新的数据去训练，甚至是实时数据训练。虽然都叫 GPT-4，但给出的答案不同，因为训练数据不同。\nQ：那我如何去判断他是否是 GPT-4 模型？ ​ # A： 可使用以下逻辑性问题进行测试。 问题： 鲁迅和周树人是什么关系？ GPT-3.5： 鲁迅和周树人是两个不同的人 GPT-4： 鲁迅和周树人是同一个人。\nQ：无法登录？ ​ # A： 请确保用户名填写正确，不要填写邮箱地址，填写你注册时的用户名。如遇到登录问题无法自行解决，请联系客服，第一时间为您处理。\nQ：为什么请求后没吐字没补全 token？ ​ # A： 有以下可能：\n快吐字了，客户端断开连接。\ntools call 或 function call。\nOpenAI 直接返回 [Done]，一般是政策安全相关拒绝回答，需要结合返回的 finish_reason 或内容进行判断。\nA： 针对不同的数据返回代码，以下是常见的错误代码：\n错误代码 代码解释 400 Bad Request 请求格式错误或无效。这通常意味着你的请求参数有误，需要你检查并修正请求参数。 401 Unauthorized 请求令牌无效。这通常意味着你的请求令牌有误，需要你检查并修正请求参数。 403 Forbidden 一般是余额不足。 404 Not Found 请求的资源未找到。你可能正在试图访问一个不存在的端点。 413 Request Entity Too Large 请求体太大。你可能需要减少你的请求数据量。 429 Too Many Requests 由于短时间内发送过多的请求，你已经超过了你的速率限制。 500 Internal Server Error 服务器内部错误。这可能是 OpenAI 服务器的问题，不是你的问题。 503 Service Unavailable 服务暂时不可用。这可能是由于 OpenAI 正在进行维护或者服务器过载。 Q：后台额度充足，使用 API 提示额度不足？ ​ # A： 请确认你后台创建的令牌已经分配好额度，过期时间一般可以设置成无限制。另外，额度不是填写金额，500000 额度 = 1 美金，可按需填写。\nQ：出现 CDN 回源报错？ ​ # A： 请联系客服获取企业客户接口地址。\nQ：提示当前分组下没有可用渠道？ ​ # A： 请确保模型名称完全和列表一致，并且区分大小写。\nQ：额度是什么? 怎么计算的？ ​ # A： 额度 = 分组倍率 * 模型倍率 * (提示 token + 补全 token * 补全倍率)。 其中补全倍率对于 GPT-3.5 固定为 1.33，GPT-4 为 2，与官方保持一致。如果是非流模式，官方接口会返回消耗的总 token，但是你要注意提示和补全的消耗倍率不一样。\nQ：什么是上下文？ ​ # A： 在 GPT 用于文本生成时，它需要考虑之前输入的所有文本上下文，以生成连贯、有意义的句子。随着输入上下文的增加，GPT 生成的文本变得越来越连贯和精准。例如，如果将一篇完整的文本或段落作为输入，GPT 将能生成符合上下文连贯性的自然语言文本。因此，GPT 上下文累积得越多，生成文本的准确度和连贯性呈逐步提升趋势。\nQ：账户额度足够为什么提示额度不足？ ​ # A： 请检查你的令牌额度是否足够，这个和账户额度是分开的。令牌额度仅供用户设置最大使用量，用户可自由设置。\nQ：ChatGPT Next Web 报错: Failed to fetch？ ​ # A： 部署的时候不要设置 BASE URL。检查你的接口地址和 API Key 有没有填对。\nQ：网站部分页面打开报错？ ​ # A： 请清理浏览器缓存和 Cookie。\nQ：为什么 gpt-4 额度消耗这么快？ ​ # A： gpt-4 的消耗速度是 gpt-3.5-turbo 的 20 到 40 倍。假设购买了 9w token，我们用 30 倍作为平均倍率，也就是 90000 / 30 = 3000 字左右，加上每次要附带上历史消息，能发的消息数将会进一步减半。在最极限的情况下，一条消息就能把 9w token 消耗完，所以请谨慎使用。\nQ：令牌无效？ ​ # A： 一般出现这种问题，可能是：\n地址写错，不是我们的地址。\n令牌没有正确的设置到程序中。\n令牌已失效，请重新生成一个新的令牌。\nQ：Failed to fetch？ ​ # A： 一般遇到这种问题，可能是你的网络环境有问题，请尝试更换网络。亦或者是你使用了错误的接口地址，请检查接口地址是否正确。\nQ：无可用渠道？ ​ # A： 检查错误中得模型名称是否存在。\nQ：构图时出现 SyntaxError：Unexpected token“\u0026lt;” …… ​ # A： 出现这个问题仍是使用了不正确的接口，需要参考上面的第三个问题换成正确接口即可解决问题。\nQ：使用 chatgpt-web-midjourney-proxy 上传失败？ ​ # A： 对于这个问题，作者已经在项目地址反复说明了很多遍： 。需要使用 docker 部署，并开启 API_UPLOADER，vercel 不支持。而且如果是在前端填写的中转地址，上传文件会跟着中转地址走。\nQ：该令牌额度已用尽？ ​ # A： 这个问题一般说明你的令牌已经没有额度了，需要给你的令牌加额度，或者你的钱包已经没有额度了，需要给你的钱包充值。\nQ：user quota is not enough？ ​ # A： 这个问题一般说明你的账户已经没有额度了，需要给你的钱包充值。\nQ：max_tokens is too large？ ​ # A： 请求参数中的 max_tokens 参数设置过大。请求携带的上下文 token 数 + max_tokens 必须小于等于模型的上下文大小。例如，gpt-4 的模型上下文是 128k，max_tokens 最大为 4096。那么必须满足 max_tokens \u0026lt;= 4096 和 请求携带的上下文 token 数 + max_tokens \u0026lt;= 128k 。\n"},{"id":32,"href":"/docs/ailearn/notice/","title":"高级功能-通知设置 · 额度预警通知","section":"站内基础教程","content":" 高级功能-通知设置 · 额度预警通知 # 🔔 事件订阅与通知配置指南 # 关键事件，实时掌控！\n订阅重要事件并设置通知渠道，额度预警、系统更新等消息即时送达，让您永远快人一步 🚨\n💻 配置入口：\n👉神马中转API个人中心\n三步配置法（以额度预警为例） # 1️⃣ 选择订阅事件\n🔍 可订阅事件清单 # 事件类型 触发条件 频率限制 推荐场景 公告通知 平台发布重要公告 无限制（实时推送） 所有用户必选 ✅ 营销信息 平台推出优惠活动/新产品 无限制（实时推送） 关注优惠活动的用户 用户额度预警 总钱包余额 \u0026lt; 您设置的阈值 ≤1条/小时（防骚扰） 所有用户必选 ✅ Key额度预警 单个API Key余额 \u0026lt; 您设置的阈值 Key独立 ≤1条/小时 管理多Key的企业用户 2️⃣ 配置通知渠道\n🔧 通知渠道配置详解 # 渠道 配置难度 适用场景 关键配置项 实时性 邮件 ⭐☆☆☆☆ 非紧急通知/存档记录 邮箱地址（自动识别登录邮箱） 5分钟内 企业微信 ⭐⭐☆☆☆ 团队协作/内部告警 企业ID + 应用Secret + AgentID 即时 钉钉 ⭐⭐☆☆☆ 企业级监控/运维警报 Webhook URL + 密钥 即时 WxPusher ⭐☆☆☆☆ 个人微信接收通知 UID（扫码绑定） 即时 Webhook ⭐⭐⭐⭐☆ 系统集成/自动化流程 API端点URL + 自定义Header/Body模板 即时 Telegram ⭐⭐☆☆☆ 国际用户/开发者 Bot Token + Chat ID 即时 3️⃣ 点击保存生效\n遇到问题？随时召唤客服！\n"},{"id":33,"href":"/docs/aidocs/pay2/","title":"基本概念-按次付费","section":"基础知识","content":" 📖基本概念-按次付费 # 💸 按次计费：像买奶茶一样简单！ # 不问字数多少，一次对话一票到底！ 就像坐地铁——无论坐1站还是10站，票价都一样\n对话场景 字数统计 按次计费 按量计费对比 简单问候 问5字 + 答15字 ✅$0.1 ❌ $0.0012 问：\u0026ldquo;你好\u0026rdquo; (固定消费) (输入$0.00015) 答：\u0026ldquo;请问需要帮助吗？\u0026rdquo; (输出$0.0009) 深度咨询 问200字+答800字 ✅$0.1 ❌ $0.054 问：\u0026ldquo;请分析2023全球\u0026hellip;\u0026rdquo; (固定消费) (输入$0.006) 答：\u0026ldquo;根据IMF报告\u0026hellip;\u0026rdquo; (输出$0.048) 💎 黄金规律：当字数 \u0026gt;1000字时，按次计费更划算！\n适用场景导航 # bash复制代码# 👍 强烈推荐使用 ➜ [ 写长文 ] [ 代码调试 ] [ 报告分析 ] [ 法律咨询 ] [ 学术修改 ] [ 剧本创作 ] # ️ 不推荐使用 ➜ [ 查天气 ] [ 简单翻译 ] [ 短问答 ] "},{"id":34,"href":"/docs/openai/wltpjx/","title":"网络图片解析","section":"Openai请求格式（通用）","content":" 网络图片解析 # 接口说明 # 通过多模态AI模型分析图片内容，理解图片、提取图片信息，包括OCR功能。\n主流图片分析模型 # 模型名称 描述 gpt-4o 目前图片分析调用量最大的模型，稳定、并发高 gemini-2.5-flash 谷歌旗舰模型，速度快，性价比好 claude-sonnet-4-20250514 图片分析做的不错，但性价比略差 doubao-1.5-vision-pro-250328 国内图片分析主流模型，性价比好，稳定、并发高 基础信息 # Base URL: https://api.whatai.cc\n请求方式: POST\nContent-Type: application/json\n接口地址 # POST /v1/chat/completions\n请求头 # 参数 类型 必填 说明 Authorization string 是 Bearer token，格式：Bearer ****** Content-Type string 是 固定值：application/json User-Agent string 否 客户端标识 请求参数 # { \u0026#34;model\u0026#34;: \u0026#34;gemini-2.0-flash-thinking-exp-1219\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;你是一个图片分析助手。\u0026#34;} ] }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;image_url\u0026#34;, \u0026#34;image_url\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;图片URL\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;分析提示词\u0026#34; } ] } ], \u0026#34;temperature\u0026#34;: 0.1, \u0026#34;user\u0026#34;: \u0026#34;whatai\u0026#34; } 参数说明 # 参数 类型 必填 说明 model string 是 模型名称，推荐：gemini-2.5-flash 或 gpt-4o messages array 是 消息内容数组 temperature float 否 生成文本的随机性，0-1之间 user string 否 用户标识 Python 调用示例 # import requests # API配置 BASE_URL = \u0026#34;https://api.whatai.cc/\u0026#34; API_ENDPOINT = BASE_URL + \u0026#34;v1/chat/completions\u0026#34; API_KEY = \u0026#34;sk-******\u0026#34; # 替换为你的API密钥 IMAGE_URL = \u0026#34;https://api.whatai.cc/111.jpg\u0026#34; # 替换为你的图片URL def analyze_image(image_url, prompt): \u0026#34;\u0026#34;\u0026#34; 图片分析函数 :param image_url: 图片URL :param prompt: 分析提示词 :return: 分析结果文本 \u0026#34;\u0026#34;\u0026#34; payload = { \u0026#34;model\u0026#34;: \u0026#34;gemini-2.0-flash-thinking-exp-1219\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;你是一个图片分析助手。\u0026#34;}] }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;image_url\u0026#34;, \u0026#34;image_url\u0026#34;: {\u0026#34;url\u0026#34;: image_url}}, {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: prompt} ] } ], \u0026#34;temperature\u0026#34;: 0.1 } headers = { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {API_KEY}\u0026#34; } try: response = requests.post(API_ENDPOINT, headers=headers, json=payload) response.raise_for_status() return response.json()[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;][\u0026#34;content\u0026#34;] except Exception as e: print(f\u0026#34;请求失败: {e}\u0026#34;) return None # 使用示例 if __name__ == \u0026#34;__main__\u0026#34;: result = analyze_image(IMAGE_URL, \u0026#34;请描述这张图片的内容\u0026#34;) if result: print(\u0026#34;分析结果:\u0026#34;, result) 常见错误码 # 状态码 说明 400 请求参数错误，看看图片是不是太大了 500 服务器内部错误 "},{"id":35,"href":"/docs/otherai/chat/chatnextweb/","title":"Chat Next Web","section":"对话客户端类","content":" Chat Next Web # "},{"id":36,"href":"/docs/openai/bdtpjx/","title":"本地图片解析","section":"Openai请求格式（通用）","content":" 本地图片解析 # 接口说明 # 通过多模态AI模型分析图片内容，支持OCR和图片信息提取功能。\n主流图片分析模型\n模型名称 描述 gpt-4o 目前图片分析调用量最大的模型，稳定、并发高 gemini-2.5-flash 谷歌旗舰模型，速度快，性价比好 claude-sonnet-4-20250514 图片分析做的不错，但性价比略差 doubao-1.5-vision-pro-250328 国内图片分析主流模型，性价比好，稳定、并发高 本地图片分析预处理 # 需要先把本地图片转为 base64 再提交给模型。\n参数说明 # model: 指定使用的AI模型\nmessages: 包含用户指令和图片数据\ntemperature: 控制输出随机性(0-1)\nimage_url: 支持Base64编码的本地图片或网络图片URL\n请求示例 # import base64 import requests def encode_image(image_path): \u0026#34;\u0026#34;\u0026#34;将本地图片编码为Base64字符串\u0026#34;\u0026#34;\u0026#34; with open(image_path, \u0026#34;rb\u0026#34;) as image_file: return base64.b64encode(image_file.read()).decode(\u0026#34;utf-8\u0026#34;) # API配置 BASE_URL = \u0026#34;https://api.whatai.cc/\u0026#34; API_ENDPOINT = BASE_URL + \u0026#34;v1/chat/completions\u0026#34; API_KEY = \u0026#34;sk-******\u0026#34; # 替换为你的API密钥 # 准备请求数据 image_data = encode_image(\u0026#34;example.png\u0026#34;) # 本地图片路径 payload = { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o\u0026#34;, # 指定分析模型 \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;请分析图片内容\u0026#34;}, { \u0026#34;type\u0026#34;: \u0026#34;image_url\u0026#34;, \u0026#34;image_url\u0026#34;: { \u0026#34;url\u0026#34;: f\u0026#34;data:image/png;base64,{image_data}\u0026#34; } } ] } ], \u0026#34;temperature\u0026#34;: 0.1 } headers = { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {API_KEY}\u0026#34; } # 发送请求 response = requests.post(API_ENDPOINT, headers=headers, json=payload) print(response.json()) # 输出响应结果 注意事项 # 图片需小于20MB\n支持PNG/JPEG格式；非普通扩展名的图片（例如.file）请先处理成base64再给模型。\n响应时间取决于图片大小和模型选择\n"},{"id":37,"href":"/docs/ailearn/keysafety/","title":"高级功能-API KEY 安全配置","section":"站内基础教程","content":" 高级功能-API KEY 安全配置 # 🔐 API Key 安全加固指南 # 密钥如金，严防盗刷！ 三大利刃全面守护您的API Key安全，杜绝泄露风险\n🛡️ 安全配置三剑客 # ⚔️ 1. IP白名单 - 网络级防护 # 作用：构建数字围墙，只有在白名单内的 IP 地址才能调用 API，其他 IP 地址的请求将被拒绝。\n令牌页 → 目标Key → 编辑 → IP白名单 ⚠️ 致命防护：\n未在白名单的IP发起请求 → 403 Forbidden\n有效拦截99%的盗刷攻击\n2. 额度预警 - 财务级护航 # 作用：实时监控消耗，预防超额损失\n个人中心页 → 通知设置 → 额度预警订阅 **🔒 3. 模型锁 - 权限级管控 -**启用模型限制 # 作用：指定某个 API Key 仅用于特定的模型，防止该 Key 被用于其他模型调用\n启用效果：\n允许： gpt-4-turbo- 拒绝： midjourney-v6（返回403错误） 令牌页 → 目标Key → 编辑 → 模型限制 🛠️ 配置实战演示 # 案例：为客服系统Key配置安全策略\nbash复制代码Step 1：进入编辑页 Key名称：AI客服生产环境 Step 2：设置IP白名单 添加 → 122.112.10.25（客服服务器IP） 添加 → 122.112.10.0/24（备用网段） Step 3：启用模型锁 勾选模型 → gpt-4-turbo-2025 勾选模型 → whisper-asr Step 4：绑定额度预警 预警阈值 → $50 通知渠道 → 企业微信+短信 🌐 攻击防护模拟测试 # # 攻击者视角（密钥泄露后）： 1. 从境外IP 58.100.2.3 发起请求 → ❌ 被IP白名单拦截 2. 伪造境内IP尝试 → ❌ 非授信IP段仍被拒 3. 尝试调用mj模型 → ❌ \u0026#34;该Key未授权此模型\u0026#34; 4. 小额盗刷测试 → ✅ 触发预警短信 → 管理员立即冻结 ⚠️ 必须规避的配置误区 # - 错误1：IP白名单留空（等于全开放） + 修正：至少添加1个IP段 - 错误2：预警阈值=$0.1（频繁干扰） + 修正：设为日均消耗的 "},{"id":38,"href":"/docs/otherai/chat/GoAmz/","title":"GoAmz","section":"对话客户端类","content":" GoAmz # "},{"id":39,"href":"/docs/ailearn/errorcode/","title":"常见报错码","section":"站内基础教程","content":" 常见报错码 # 错误排查指南 # 遇到错误时，请先查看返回的错误码，然后参考下表进行排查处理。\n错误码对照表 # 状态码 说明 解决方案 400 请求格式错误 检查请求参数，例如o1系列模型不支持system参数 401 无效令牌 检查API密钥是否正确，可换模型测试验证 403 令牌分组被禁用 编辑令牌取消限额或新建令牌 404 接口不存在 检查Base URL是否正确，尝试添加/v1或斜杠/ 413 请求内容过长 缩短prompt内容后重试 429 上游限流 账号并发过高，稍后重试 500 服务器内部错误 多次重试仍失败请联系管理员 503 模型不可用 当前分组无该模型渠道，请检查模型名称是否正确，有没有多空格少空格之类。 504 网关超时 上游服务器未及时响应，稍后重试 524 连接超时 通道拥挤，稍后重试 解答 # 400 错误码，一般是请求参数不匹配。先把 system 注释掉，先试试通不通。\n401 错误码 “无效令牌”，是因为令牌和API地址URL错配了。\n403 错误码，一般是 令牌额度 不够了（令牌额度和账户额度是两个概念）。 到令牌编辑里，点 “设为无限额度” 就可以了，一般等2分钟就能生效。 也可以新建一个令牌“设为无限额度”，试一下。\n404 错误码，大概率是 API地址 没正确设置。\n429 错误码，是模型达到流量限制的体现。简单说就是：用的人太多 造成模型达到 TPM 饱和了。 一般情况下，等会重试就可以使用。 如果持续不能使用，把模型名称给客服，客服会排查处理。\n503 错误码，请检查模型全称有没有错，模型全称到 顶部菜单 支持模型 页面查看。 如果模型名称没错，把模型名称发给客服，客服进行排查处理。\n"},{"id":40,"href":"/docs/openai/functioncall/","title":"函数调用FunctionCall","section":"Openai请求格式（通用）","content":" 函数调用FunctionCall # 概念介绍 # 函数调用(Function Calling\\Tools Calling)是AI大模型的一种能力。允许大语言模型在对话过程中调用外部函数/工具。当用户提问需要实时数据(如天气、股票等)时，模型会返回函数调用请求，开发者可以在后端执行相应函数并返回结果。\nAPI 基础信息 # 请求地址: https://api.whatai.cc/v1/chat/completions\n请求方法: POST\n认证方式: Bearer Token\n请求示例 # import http.client import json # 创建HTTPS连接 conn = http.client.HTTPSConnection(\u0026#34;api.whatai.cc\u0026#34;) # 构造请求体 payload = json.dumps({ \u0026#34;model\u0026#34;: \u0026#34;gpt-4o\u0026#34;, # 指定模型 \u0026#34;max_tokens\u0026#34;: 300, # 最大返回token数 \u0026#34;temperature\u0026#34;: 0.8, # 生成结果的随机性控制 \u0026#34;stream\u0026#34;: False, # 是否流式输出 \u0026#34;messages\u0026#34;: [{ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;上海今天几度？\u0026#34; # 用户提问 }], \u0026#34;tools\u0026#34;: [{ # 定义可用工具 \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, # 函数名称 \u0026#34;description\u0026#34;: \u0026#34;获得天气信息\u0026#34;, # 功能描述 \u0026#34;parameters\u0026#34;: { # 参数定义 \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { # 必填参数：地点 \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;城市和州名，例如：上海, 中国\u0026#34; }, \u0026#34;unit\u0026#34;: { # 可选参数：温度单位 \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;] } }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;] # 必填参数列表 } } }] }) # 请求头设置 headers = { \u0026#34;Accept\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer sk-**********************\u0026#34;, # 替换为你的 API 令牌 \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } # 发送请求 conn.request(\u0026#34;POST\u0026#34;, \u0026#34;/v1/chat/completions\u0026#34;, payload, headers) # 获取响应 res = conn.getresponse() data = res.read() # 输出结果 print(data.decode(\u0026#34;utf-8\u0026#34;)) 响应处理 # 当用户提问需要调用函数时，API会返回包含函数调用信息的JSON响应。开发者需要：\n解析响应中的函数调用请求\n在后端执行对应函数\n将函数结果再次发送给API获取最终回答\n注意事项 # 请妥善保管API密钥，不要泄露\n函数定义中的description很重要，会影响模型是否/如何调用该函数\n温度参数(temperature)控制生成结果的随机性，值越大结果越多样\nTools 场景示例 # ==========\n例如\n用户提问：“北京天气怎么样？”\n我们定义一个工具 get_weather(city: string)\nget_weather 函数需要用户开发者自己实现\n✅ 第一步：发送用户提问 + 工具定义 # curl --location --request POST \u0026#39;https://api.whatai.cc/v1/chat/completions\u0026#39; \\ --header \u0026#39;Authorization: Bearer $API_KEY\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data-raw \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;gpt-4o\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;北京天气怎么样？\u0026#34; } ], \u0026#34;tools\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;获取城市天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;city\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;城市名称，例如 北京\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;city\u0026#34; ] } } } ], \u0026#34;tool_choice\u0026#34;: \u0026#34;auto\u0026#34; }\u0026#39; 📥 AI 返回内容（模型决定调用 get_weather）：\n{ \u0026#34;choices\u0026#34;: [ { \u0026#34;message\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;toolcall-abc123\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{ \\\u0026#34;city\\\u0026#34;: \\\u0026#34;北京\\\u0026#34; }\u0026#34; } } ] } } ] } 🔁 第二步：你执行实际函数（例如自己写的天气 API），并将结果通过工具响应发回 AI # 假设你查询天气后得到：\n{ \u0026quot;temperature\u0026quot;: \u0026quot;31°C\u0026quot;, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot; }\n那么你现在发送的是 完整上下文 + tool 响应：\ncurl --location --request POST \u0026#39;https://api.whatai.cc/v1/chat/completions\u0026#39; \\ --header \u0026#39;Authorization: Bearer $API_KEY\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data-raw \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;gpt-4o\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;北京天气怎么样？\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;toolcall-abc123\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;arguments\u0026#34;: \u0026#34;{ \\\u0026#34;city\\\u0026#34;: \\\u0026#34;北京\\\u0026#34; }\u0026#34; } } ] }, { \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: \u0026#34;toolcall-abc123\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{ \\\u0026#34;temperature\\\u0026#34;: \\\u0026#34;31°C\\\u0026#34;, \\\u0026#34;condition\\\u0026#34;: \\\u0026#34;晴\\\u0026#34; }\u0026#34; } ] }\u0026#39; ✅ 第三步：返回最终的自然语言回复（例如）： # { \u0026#34;choices\u0026#34;: [ { \u0026#34;message\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;北京今天是晴天，气温为 31°C。适合出门哦！\u0026#34; } } ] } "},{"id":41,"href":"/docs/otherai/chat/SparkAI/","title":"SparkAI","section":"对话客户端类","content":" SparkAI # "},{"id":42,"href":"/docs/openai/whisper/","title":"whisper使用示例","section":"Openai请求格式（通用）","content":" whisper使用示例 # whisper 模型接口说明 # 该接口基于 Whisper 模型实现语音转文本功能，支持常见音频格式。\n基础概念 # Whisper模型: OpenAI 开源的语音识别模型，支持多语言转写\n音频格式: 支持 mp3、wav、m4a 等常见格式\n接口地址 # POST https://api.whatai.cc/v1/audio/transcriptions\n请求参数 # 参数名 类型 必填 说明 model string 是 固定值 \u0026ldquo;whisper-1\u0026rdquo; file file 是 要转写的音频文件 请求头 # Authorization: Bearer sk- **** **** **** **** **** * # 替换为你的 API 令牌\nPython 调用示例 # import json import requests def voice_to_text(file_path): \u0026#34;\u0026#34;\u0026#34; 语音转文本功能 参数: file_path: 音频文件路径 返回: 识别出的文本内容 \u0026#34;\u0026#34;\u0026#34; url = \u0026#34;https://api.whatai.cc/v1/audio/transcriptions\u0026#34; # 构造请求参数 payload = {\u0026#34;model\u0026#34;: \u0026#34;whisper-1\u0026#34;} files = {\u0026#34;file\u0026#34;: (\u0026#34;audio.mp3\u0026#34;, open(file_path, \u0026#34;rb\u0026#34;))} # 设置请求头(请替换为你的API密钥) headers = {\u0026#34;Authorization\u0026#34;: \u0026#34;Bearer sk-***************************\u0026#34;} # 替换为你的 API 令牌 # 发送POST请求 response = requests.post(url, headers=headers, data=payload, files=files) # 解析响应数据 data = json.loads(response.text) # 返回识别结果 return data.get(\u0026#34;text\u0026#34;, \u0026#34;\u0026#34;) # 使用示例 print(voice_to_text(\u0026#34;audio.mp3\u0026#34;)) # 替换为你的音频文件路径 响应示例 # 成功响应:\n{ \u0026#34;text\u0026#34;: \u0026#34;这是识别出的文本内容\u0026#34; } 注意事项 # 音频文件大小建议不超过25MB\n支持中文、英文等多种语言\n请妥善保管API密钥，不要泄露\n"},{"id":43,"href":"/docs/openai/gpttts/","title":"gpt-tts","section":"Openai请求格式（通用）","content":" gpt-tts # 接口说明 # 提供基于 gpt-4o-mini-tts TTS 模型的文本转语音服务，支持多种音色选择。\n基础概念 # TTS(Text-to-Speech): 将文本转换为自然语音的技术\n音色(Voice): 合成语音的声音特征，本API支持多种预设音色\n请求地址 # POST https://api.whatai.cc/v1/audio/speech\n请求头 # headers = { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer ******\u0026#34;, # 替换为您的API密钥 \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } 请求参数 # 参数名 类型 必填 说明 model string 是 固定值 \u0026ldquo;gpt-4o-mini-tts\u0026rdquo; input string 是 需要转换为语音的文本内容 voice string 是 音色类型，如 \u0026ldquo;alloy\u0026rdquo; Python 调用示例 # import requests import json url = \u0026#34;https://api.whatai.cc/v1/audio/speech\u0026#34; api_key = \u0026#34;******\u0026#34; # 替换为您的API密钥 payload = { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini-tts\u0026#34;, \u0026#34;input\u0026#34;: \u0026#34;我是API，欢迎使用语音合成服务\u0026#34;, \u0026#34;voice\u0026#34;: \u0026#34;alloy\u0026#34; } try: # 发送POST请求 response = requests.post(url, headers={\u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {api_key}\u0026#34;}, json=payload) # 检查响应状态 response.raise_for_status() # 处理音频响应 if response.headers[\u0026#34;Content-Type\u0026#34;] in (\u0026#34;audio/mpeg\u0026#34;, \u0026#34;audio/mp3\u0026#34;): with open(\u0026#34;output.mp3\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(response.content) # 写入音频文件 print(\u0026#34;语音合成成功，已保存为output.mp3\u0026#34;) else: print(\u0026#34;错误响应:\u0026#34;, response.text) except Exception as e: print(f\u0026#34;请求出错: {e}\u0026#34;) 响应说明 # 成功: 返回MP3格式的音频流，Content-Type为audio/mpeg\n失败: 返回JSON格式的错误信息\n注意事项 # API密钥需妥善保管，不要暴露在客户端代码中\n输入文本长度建议不超过500字符\n音频采样率为24kHz，比特率128kbps\n"},{"id":44,"href":"/docs/otherai/chat/nineai/","title":"NineAI(99AI) ","section":"对话客户端类","content":" NineAI(99AI) # "},{"id":45,"href":"/docs/openai/gptwst/","title":"gpt文生图","section":"Openai请求格式（通用）","content":" gpt文生图 # 概念介绍 # 文生图(Text-to-Image)是一种通过自然语言描述生成对应图像的技术。本API基于OpenAI的GPT模型实现，支持多种图像生成模型和尺寸规格。\n基础信息 # 请求方式: POST\nBase URL: https://api.whatai.cc\n接口路径: /v1/images/generations\n认证方式: Bearer Token\n请求参数 # 参数名 类型 必填 说明 prompt string 是 图像描述文本 n int 否 生成图片数量(默认1) model string 否 模型选择(默认gpt-image-1) aspect_ratio string 否 宽高比(如\u0026quot;16:9\u0026quot;) size string 否 图像尺寸(如\u0026quot;1024x1536\u0026quot;) seed int 否 随机种子(-1表示随机) 支持的模型 # gpt-image-1: 基础模型(支持1024x1024,1024x1536,1536x1024)\nseedream-3.0: 国内最强，豆包团队开发，即梦3 AI绘图大模型。\ngpt-image-1: Openai GPT 的画图模型，文本理解与图像生成深度融合，适合文字驱动型创作\nimagen4: 谷歌的绘图模型，对标 gpt-image\nflux-kontext-max: Black Forest Labs推出商业级精度的图像生成，满足专业设计需求\nflux-kontext-pro: 支持文本+图像输入的上下文感知生成/编辑模型，控制更精准。\nPython调用示例 # import json import requests # API配置 API_KEY = \u0026#34;sk-********************\u0026#34; # 替换为你的API密钥 API_URL = \u0026#34;https://api.whatai.cc/v1/images/generations\u0026#34; # 请求参数 payload = { \u0026#34;prompt\u0026#34;: \u0026#34;哪吒竖着大拇指，背景广告牌写着 API\u0026#34;, # 图像描述 \u0026#34;n\u0026#34;: 1, # 生成数量 \u0026#34;model\u0026#34;: \u0026#34;gpt-image-1\u0026#34;, # 使用基础模型 \u0026#34;size\u0026#34;: \u0026#34;1024x1536\u0026#34;, # 图像尺寸 \u0026#34;seed\u0026#34;: -1 # -1 代表随机种子 } headers = { \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {API_KEY}\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } try: # 发送POST请求 response = requests.post(API_URL, json=payload, headers=headers) response.raise_for_status() # 检查HTTP错误 # 解析响应数据 result = response.json() print(json.dumps(result, indent=4, ensure_ascii=False)) except requests.exceptions.RequestException as e: # 错误处理 print(f\u0026#34;请求失败: {e}\u0026#34;) if e.response: print(f\u0026#34;状态码: {e.response.status_code}\u0026#34;) print(f\u0026#34;响应内容: {e.response.text}\u0026#34;) 响应示例 # 图片返回base64需要转为png图片格式。\n成功响应将返回包含生成图像信息的JSON对象，其中可能包含：\ndata: 图像数据数组\nurl: 图像访问URL(部分模型)\nb64_json: Base64编码的图像数据\n{ \u0026#34;created\u0026#34;: 1677664795, \u0026#34;data\u0026#34;: [ { \u0026#34;url\u0026#34;: \u0026#34;https://.../generated-image.png\u0026#34;, \u0026#34;b64_json\u0026#34;: \u0026#34;...\u0026#34; } ] } 常见错误码： # 401: 认证失败(无效API密钥)\n400: 请求参数错误\n429: 请求频率限制\n500: 服务器内部错误\n建议在代码中添加完善的错误处理逻辑，如示例中所示。\n详细教程神马中转 # 🎨 神马中转API 2025超强画图模型天团驾到！ # \u0026ldquo;不会画画的API不是好艺术家\u0026rdquo; - 神马中转API用户如是说\n欢迎来到《手把手教你玩转AI画图》！这里有一群身怀绝技的\u0026quot;数字达芬奇\u0026quot;，随你调遣~\n🌟 模型天团简历（2025顶配版） # 模特名 后台大佬 必杀技 身价（每张） seedream-3.0 字节跳动豆包 文生图闪电侠⚡️ ￥0.08 (~免费10万张!) gpt-image-1 OpenAI 改图/合图魔术师🎩 ￥1+ imagen4 谷歌 GPT-image的宿敌👊 待定 flux-kontext Black Forest 商业级精修大师🖋️ ￥0.2~0.4 📌 温馨提示：\n不同模特在不同场景表现迥异，建议多约会试试~（比如seedream适合批量创作，gpt-image擅长精修）\n🚀 上车指南 # 1️⃣ 领钥匙：在 https://api.whatai.cc/token 获取API密钥\n2️⃣ 选车站：\nAPI_HOST = \u0026#34;api.whatai.cc\u0026#34; 💫 模特A：seedream-3.0（文生图小旋风） # import base64, http.client, json, os, time # 配置你的魔法棒🔮 API_KEY = \u0026#34;sk-******\u0026#34; # 此处填你的阿拉丁神灯密码 prompt = \u0026#34;漫画风格英语学习图：Hello单词记忆引导\u0026#34; # 你的脑洞有多大，舞台就有多大！ size = \u0026#34;1664x936\u0026#34; # 常用尺寸任选：16:9(宽屏) | 1:1(Ins风) | 9:16(手机壁纸) # 开始召唤！ conn = http.client.HTTPSConnection(\u0026#34;api.whatai.cc\u0026#34;) conn.request(\u0026#34;POST\u0026#34;, \u0026#34;/v1/images/generations\u0026#34;, json.dumps({ \u0026#34;prompt\u0026#34;: prompt, \u0026#34;model\u0026#34;: \u0026#34;seedream-3.0\u0026#34;, \u0026#34;size\u0026#34;: size, \u0026#34;response_format\u0026#34;: \u0026#34;b64_json\u0026#34; # 必选！否则收不到图片快递 }), headers={\u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {API_KEY}\u0026#34;}) # 拆快递啦~ res = conn.getresponse() if res.status == 200: img_data = json.loads(res.read())[\u0026#34;data\u0026#34;][0][\u0026#34;b64_json\u0026#34;] with open(f\u0026#34;seedream_{int(time.time())}.png\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(base64.b64decode(img_data)) print(\u0026#34;🎉 你的大作已空投到文件夹！\u0026#34;) else: print(f\u0026#34;❌ 模特罢工了：{res.status} {res.reason}\u0026#34;) 💡 冷知识：当前免费额度能生成10万张图，够你把《蒙娜丽莎》画成表情包全集！\n🎩 模特B：gpt-image-1（PS战神） # import requests # 准备整容手术台 api_key = \u0026#34;sk-******\u0026#34; files = [ (\u0026#34;image\u0026#34;, (\u0026#34;原图.jpg\u0026#34;, open(\u0026#34;哪吒.jpg\u0026#34;, \u0026#34;rb\u0026#34;), \u0026#34;image/jpeg\u0026#34;)), # 要改造的对象 # (\u0026#34;image\u0026#34;, (\u0026#34;背景.jpg\u0026#34;, ...)) # 多图合并时加此项 ] payload = {\u0026#34;prompt\u0026#34;: \u0026#34;给哪吒戴上炫酷红色鸭舌帽\u0026#34;} # 你的改造指令 # 开始施法！ r = requests.post( \u0026#34;https://api.whatai.cc/v1/images/edits\u0026#34;, headers={\u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {api_key}\u0026#34;}, files=files, data=payload ) # 见证奇迹时刻✨ if r.status_code == 200: img_data = r.json()[\u0026#34;data\u0026#34;][0][\u0026#34;b64_json\u0026#34;] with open(\u0026#34;潮酷哪吒.png\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(base64.b64decode(img_data)) print( 🌟 模特C：flux-kontext（商业级精修大师） # import requests import os import base64 from time import sleep # 准备你的魔法工具箱🛠️ API_KEY = \u0026#34;sk-******\u0026#34; # 你的专属魔法通行证 target_img = \u0026#34;沙漠.jpg\u0026#34; # 需要点石成金的照片 print(\u0026#34;🔮 正在召唤商业级修图精灵flux-kontext...\u0026#34;) sleep(1) # 加点魔法特效等待时间 try: # 开始施展专业级图像魔法 response = requests.post( \u0026#34;https://api.whatai.cc/v1/images/edits\u0026#34;, # 国际站小伙伴请用.com headers={\u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {API_KEY}\u0026#34;}, files=[(\u0026#34;image[]\u0026#34;, (os.path.basename(target_img), open(target_img, \u0026#34;rb\u0026#34;), \u0026#34;image/jpeg\u0026#34;))], data={ \u0026#34;model\u0026#34;: \u0026#34;flux-kontext-max\u0026#34;, # 可选：flux-kontext-pro（速度型）｜ flux-kontext-max（质量型） \u0026#34;prompt\u0026#34;: \u0026#34;给沙漠照片添加绿洲和彩虹\u0026#34;, # 你的想象力是唯一的限制 \u0026#34;quality\u0026#34;: \u0026#34;high\u0026#34; # 品质选项：low（快但糙）｜ medium｜ high（慢但精） } ) # 检查魔法是否生效 if response.status_code == 200: print(\u0026#34;🌈 魔法生效中...专业精灵正在精修您的照片\u0026#34;) img_data = response.json()[\u0026#34;data\u0026#34;][0][\u0026#34;b64_json\u0026#34;] # 保存你的魔法杰作 with open(\u0026#34;沙漠奇迹.jpg\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(base64.b64decode(img_data)) print(\u0026#34;🎨 专业级大片已生成！建议立即设为壁纸炫耀~\u0026#34;) else: print(f\u0026#34;🧙‍♂️ 啊哦，魔法失灵了！错误代码：{response.status_code}\u0026#34;) print(f\u0026#34;🔍 详细原因：{response.text[:100]}...\u0026#34;) # 显示部分错误信息 except Exception as e: print(f\u0026#34;⚠️ 魔法反噬警告：{str(e)}\u0026#34;) print(\u0026#34;💡 小贴士：检查图片路径 | 网络连接 | API密钥有效性\u0026#34;) finally: print(\u0026#34;✨ 本次魔法仪式结束，期待您下次召唤！\u0026#34;) 专业小贴士：\nflux-kontext-pro和flux-kontext-max就像魔法学徒和魔法大师——前者快，后者强\n遇到复杂魔法（大图精修）时，喝杯咖啡耐心等待☕️\nquality参数是质量与速度的平衡术，按需调配\n❤️ 真爱提示 # 密钥保管：千万别把sk-***发到网上，否则你的AI模特会被别人拐跑！\n错误处理：遇到错误先检查——\n✔️ 域名写对了吗？\n✔️ 图片路径正确吗？\n✔️ 免费额度用完啦？\n玩得开心：多尝试不同咒语(prompt)，你会打开新世界大门！ 最后，神马中转API团队为你打Call：\u0026ldquo;让每个创意都轻松落地，是我们不变的初心~ ✨\u0026rdquo;\n🎉 毕业典礼 \u0026amp; 防坑指南 # # 所有模特通用的生存法则 print(\u0026#34;\u0026#34;\u0026#34; 🌟 三大黄金定律 🌟 1. 密钥保管好 -\u0026gt; 别让sk-***出现在GitHub上！ 2. 域名要选对 -\u0026gt; .cn还是.com？错配会变404幽灵👻 3. 尺寸看清楚 -\u0026gt; 别让16:9的美图硬塞进1:1相框！ \u0026#34;\u0026#34;\u0026#34;) print(\u0026#34;🎓 恭喜你完成AI画图大师课程！现在去征服世界吧~\u0026#34;) ✨ 教程到此结束，但你的创作之旅才刚刚开始！快去生成你的第一幅AI杰作吧~\n"},{"id":46,"href":"/docs/openai/gpttst/","title":"gpt图生图","section":"Openai请求格式（通用）","content":" gpt图生图 # 概念介绍 # 本API提供图像编辑功能，支持：\n单图修改：基于提示词对单张图片进行内容修改\n多图合并：将多张图片按提示词要求合并处理\n基础信息 # 请求方式：POST\nBase URL：https://api.whatai.cc/v1/images/edits\n认证方式：Bearer Token\n单图修改示例\nPython代码示例 # import base64 import json import requests # API配置 url = \u0026#34;https://api.whatai.cc/v1/images/edits\u0026#34; api_key = \u0026#34;sk-******\u0026#34; # 替换为你的API密钥 headers = { \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {api_key}\u0026#34; } # 请求参数 payload = { \u0026#34;prompt\u0026#34;: \u0026#34;给哪吒带上一个红色的鸭舌帽，风格保持不变\u0026#34;, # 编辑指令 # \u0026#34;size\u0026#34;: \u0026#34;1024x1024\u0026#34; # 可选输出尺寸 } # 准备图片文件 files = [ (\u0026#34;image\u0026#34;, # 固定参数名 (\u0026#34;nezha.png\u0026#34;, # 文件名 open(\u0026#34;/path/to/nezha.png\u0026#34;, \u0026#34;rb\u0026#34;), # 文件路径 \u0026#34;image/png\u0026#34;) # 文件类型 ) ] # 发送请求 response = requests.post(url, headers=headers, data=payload, files=files) # 处理响应 if response.status_code == 200: try: data = response.json() # 提取base64编码的图片数据 if data.get(\u0026#34;data\u0026#34;) and isinstance(data[\u0026#34;data\u0026#34;], list): image_b64 = data[\u0026#34;data\u0026#34;][0].get(\u0026#34;b64_json\u0026#34;) if image_b64: # 解码并保存图片 with open(\u0026#34;output.png\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(base64.b64decode(image_b64)) print(\u0026#34;图片保存成功\u0026#34;) else: print(\u0026#34;未获取到有效图片数据\u0026#34;) else: print(\u0026#34;响应数据结构异常\u0026#34;) except json.JSONDecodeError: print(\u0026#34;JSON解析失败\u0026#34;) else: print(f\u0026#34;请求失败: {response.status_code}\u0026#34;) 参数说明 # 参数名 必选 类型 说明 image 是 file 要编辑的图片文件 prompt 是 string 编辑指令描述 size 否 string 输出图片尺寸，如\u0026quot;1024x1024\u0026quot; 响应格式 # 成功响应示例：\n{ \u0026#34;data\u0026#34;: [ { \u0026#34;b64_json\u0026#34;: \u0026#34;base64编码的图片数据\u0026#34; } ] } 注意事项 # 图片文件需小于10MB\n支持PNG/JPEG格式\n编辑效果取决于提示词描述的准确性\n敏感操作需确保符合内容政策\n"}]